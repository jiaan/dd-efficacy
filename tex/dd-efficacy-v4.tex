\documentclass[pra,reprint,superscriptaddress]{revtex4-2}

\usepackage{amssymb,amsthm,bm,mathrsfs,mathtools}
\usepackage[usenames]{xcolor}

\usepackage{graphicx,subcaption}
\graphicspath{{../"img/"}{../"figures/"}}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    citecolor=magenta,
    linkcolor=blue,   
    urlcolor=blue,
}

\bibliographystyle{apsrev4-2}
\def\biblio{\bibliography{references}}


\usepackage{mycommands}
\newcommand{\Dmax}{\trdis_\mathsf{max}}
\newcommand{\InFmax}{\infid_\mathsf{max}}
\newcommand{\Psb}{\mathcal{P}_\mathrm{SB}}
\newcommand{\Odd}{\Omega_{\mathsf{DD}}}
\newcommand{\Opdd}{\Omega_{\mathsf{PDD}}}
\newcommand{\vOpdd}{\vec{\Omega}_{\mathsf{P}}}
\newcommand{\LO}[1]{\operatorname{LO}}

\newcommand{\Ppb}{\mathscr{P}_{\mathrm{0}}}
\newcommand{\Pcp}{\mathscr{P}_{\mathrm{c}}}
\newcommand{\wt}[1]{\widetilde{#1}}

\newcommand{\HB}{H_\mathrm{B}}
\newcommand{\HSB}{H_\mathrm{SB}}

\newcommand{\Heff}{H_\mathrm{eff}}
\newcommand{\HeffB}{H_\mathrm{eff,B}}
\newcommand{\HeffSB}{H_\mathrm{eff,SB}}

\newcommand{\ep}{\Phi_\mathrm{SB}}
\newcommand{\wtep}{\widetilde{\Phi}_\mathrm{SB}}
\newcommand{\epB}{\Phi_\mathrm{B}}

\newcommand{\CDDn}{\mathsf{CDD}_n}
\newcommand{\rDD}{\mathrm{DD}}
\newcommand{\rmax}{\mathrm{max}}

\begin{document}

\title{Efficacy of noisy dynamical decoupling}
\author{Jiaan Qi}
\affiliation{Yale-NUS College, Singapore}

\author{Xiansong Xu}
\author{Dario Poletti}
\affiliation{Singapore University of Technology and Design}
\author{Hui Khoon Ng}
\affiliation{Yale-NUS College, Singapore}
\affiliation{Centre for Quantum Technologies, National University of Singapore}
\affiliation{MajuLab, International Joint Research Unit UMI 3654,
CNRS-UCA-SU-NUS-NTU, Singapore}


\begin{abstract}
\blue{(To be edited.)}
This paper study dynamical decoupling (DD), a family of pulse schemes aimed at removing noise in quantum systems. We first review the formalism of DD with an emphasis on the error phase, a figure-of-merit characterizing the performance of DD. We then develop noise suppression criteria from the error phase perspective for the periodic and concatenated DD schemes. A rigorous proof for the noise decoupling order of  concatenated DD is also presented.
\end{abstract}

\maketitle




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The adverse effects of noise remains the single biggest obstacle to the realisation of large-scale quantum technologies. The very quantum effects that give quantum technologies their edge over classical devices are extremely fragile and easily destroyed by the presence of unwanted interactions with the environmentâ€”noise. Much of the current research and technological push in the community today are centered around implementing methods to remove the effects of noise in quantum devices.

A key noise-removal technique is dynamical decoupling (DD)~\cite{viola1999dynamical,duan1998pulse,zanardi1999symmetrizing,khodjasteh2005fault,khodjasteh2007performance,viola2006randomized,uhrig2007keeping,pasini2010optimized,wang2011protection,ng2011combining,kuo2011quadratic}, a low-resource-cost approach that only requires application of fast pulse sequences on individual qubits in the quantum device to average away the effects of noise processes slow compared to the pulse time. With its roots in spin-echo techniques in NMR systems, DD has been used in many different types of experiments as a simple way to reduce noise in quantum information processing systems. Such active noise removal scheme is in direct contrast with the widely studied approach of quantum error correction (QEC)~\cite{Lida2013book}.
Compared with QEC,  dynamical decoupling is typically more economical as it
require no encoding of logical qubits using multiple physical qubits, nor real-time close-loop control through periodic syndrome measurement. All that is needed are regular single-qubit fast pulses that are usually easy to implement. DD be used by itself, or as the first layer of defense against noise In practice, one can choose to only implement DD or to incorporate DD within a standard QEC scheme as the low-level noise-reduction approach. 

The use of DD does not, however, come at no cost. To implement it, one has to apply multiple pulses, which can be imperfect. On the one hand, if the DD pulses are perfect, the slow noise will be averaged away, leaving weaker residual noise on the system; on the other hand, if the DD pulses are imperfect, those imperfections can add errors to the system, and if those errors happen often enough, they can eliminate the benefit of having DD in the first place. Like the cost-benefit analysis familiar to fault-tolerant quantum computing, one has to ask whether there is an error threshold for DD, limiting the level of imperfections allowed in the DD pulses above which DD simply cannot offer any benefit. 

\bigskip
\noindent\blue{More to come.}



\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
%%%%%%%%%
\subsection{DD basics}

Dynamical decoupling (DD) involves the repeated application of a fixed sequence of short pulses (or fast gates) to individual quantum registers---usually qubits---that averages away the effect of any noise with a time scale slow compared to the sequence time. 


A DD scheme is essentially a recipe specifying how a particular sequence of pulses should be applied. This consists of an ordered list of gates  
$(P_1, P_2, \cdots, P_L)$, together with their application time $(t_1, t_2,\cdots t_L)$, which is assumed to lie within the time interval $[t_0, t_L]$. 
All DD schemes share some fundamental similarities. 
First, the gates are chosen from a specified group of transformations $P_i \in \sG,\ \forall i$.
Second, any DD sequence satisfies the constraint that the gates product to identify:
\begin{equation}\label{eq:fundamental-constraint}
    P_L P_{L-1} \cdots P_1 \stackrel{\textbf{.}}{=} I,
\end{equation}
where the operators proceeds from right to left in time; the dot above the equal sign means ``up to an overall phase factor". This constraint ensures that there is no net transformation on the quantum register at the completion of the sequence. 
Different strategies could differ in the following aspects:
(i) the transformation group $\sG$.---For a qubit register, an obvious choice is perhaps the Pauli group generated by the Pauli operators $X,Y$, and $Z$. Simpler schemes such as spin echo \cite{Hahn1950} and the CPMG sequence \cite{Carr1954,Meiboom1958} use only the subgroup $\{I,Z\}$.  
(ii) the sequence length $L$ and the specific sequence of pulses.
(iii) the pulse times.---One can have regular-interval pulses, with $t_{i+1}-t_{i}$ remaining constant  for all $i$, as is the case in the periodic DD (PDD) \cite{viola1999dynamical} and concatenated DD (CDD) \cite{khodjasteh2005fault} schemes. One could, however, have variable-interval schemes, such as the Uhrig DD (UDD) sequence \cite{uhrig2007keeping}, nested UDD \cite{wang2011protection}, and quadratic DD \cite{kuo2011quadratic}.


In this work, we focus on schemes of PDD and CDD, 
two closed related schemes that both employ gates drawn from the Pauli group
and have regular gate intervals. 
\blue{The restriction to regular-interval schemes is of practical relevance.
Typcially there is no way to place two pulses arbitrary close to each other given technological constraints. Also in many cases quantum gates are encapsulated as black boxes whose implementation cannot be altered. Hence the overall physical picture here is a quantum circuit working under fixed frequency, with time $\tau$ in between consecutive gates. }
A nonzero $\tau$ can be simply the finite switch time between gates, or there may be other practical reasons for a synchronized clock cycle time. 
\blue{The control gates within a DD sequence are modeled as 
sharp pulses. We illustrate a typcial sequence of DD control gates in \Figref{fig:pulses}. }
\begin{figure}[htbp]
 \includegraphics[width=1\linewidth]{pulse.pdf}
 \caption{\blue{Illustration of a typical DD sequence.
In the diagram, different control gates/pulses are filled with different colors. The imaginary gate (dashed)  at $t_0$ corresponds to the last gate from the previous cycle.} }
 \label{fig:pulses}
\end{figure}

There are two sources of errors: (i) the system---the quantum register---interacts with a bath, and that interaction is the source of noise on the system, present even in the absence of the DD pulses; (ii) the pulse imperfections. In past work (see, for example, Ref.~\cite{khodjasteh2005fault}), imperfect DD pulses were modeled as finite-duration pulses during which the alway-on system-bath interaction acts and leads to errors in the pulses. Here, we allow for the more general, and practically relevant, situation of additional control errors in the pulses. We model noisy finite-duration pulses as instantaneous ideal pulses followed by a noise map that captures the background noise as well as any additional control errors. DD sequences are ideally designed to average away the background noise arising from the system-bath interaction. We refer to the original DD sequences with perfect instantaneous pulses as ideal DD, and to the case with imperfect pulses as noisy DD.

In the absence of any DD pulses, the system and bath evolve jointly according to the Hamilton operator $H$, assumed to be time-independent as is appropriate for standard DD analysis (put differently, any parametric time dependence in the joint dynamics occurs because of degrees of freedom excluded from the bath; here we think of all such degrees of freedom as part of the bath). $H$ here can be written as $H=\HB +\HSB$, with $\HB$ as the bath-only Hamilton operator, and $\HSB$ the interaction. No system-only term appears in $H$ as we assume no nontrivial dynamics (other than that arising from $\HSB$) occur in the system during the DD period. With this, we can write the evolution operator for ideal DD as
\begin{equation}\label{eq:Udd}
U_\mathrm{DD}\equiv P_L\upe^{-\upi\tau H}P_{L-1}\ldots P_2\upe^{-\upi\tau H}P_1\upe^{-\upi\tau H}\equiv\upe^{-\upi\Odd}.
\end{equation}
Here, we have defined $\Odd\equiv T\Heff $ as the dimensionless (with the $T$ factor) effective Hamilton operator appropriate for describing evolution for the time of the DD sequence.
$\Odd$ can be written down formally using the Magnus expansion,
\begin{equation}\label{eq:Oeff Magnus series}
\Odd  = \sum_{m=1}^\infty \Odd\up{m},
\end{equation}
where the $m$th term consists of of products of $m$ copies of $\tau H$, and hence of order $\Vert \tau H \Vert^m$. We refer the reader to past analyses of DD \red{(cite)} for a detailed derivation; here we provide only the basic expressions needed for our discussion below. \blue{(Add back a bit of the derivation of the $\Odd^{(1)}$ and $\Odd^{(2)}$ terms.)} Within the radius of convergence of the Magnus series, $\Odd^{(m)}$ decreases in importance as $m$ increases. A DD scheme such that $\Odd^{(m)}$ acts trivially on the system (i.e., acts as $I$ on system) for all $m\leq n$ is said to achieve $n$th-order decoupling---the system sees weakened noise, of strength $\Vert\Odd^{(n)}\Vert\sim\Vert \tau H\Vert^n$, compared to $\Vert\Odd^{(1)}\Vert\sim\Vert \tau H\Vert$ without DD.

\subsection{Quantifying the efficacy of DD}
\subsubsection{Decoupling Order}


According to \Eqref{eq:formal-Odd}, the DD protocol can be regarded as a transformation $\Omega \to \Odd$. Since the noise map $\cE$ is a function of $\Omega$ and $\rhoB$, the transformation on $\Omega$ takes the original quantum channel into a new 
one  $\cE\to\cE_\sDD$. 
As is argued in Sec.~\!\ref{sec:errph.vs.inf}, error phase is a convenient characterization of noise strength, we apply the two-component norm to the dimensionless Hamiltonian before and after DD, leading to 
\begin{align}
    \opnorm{\Omega} \equiv (\alpha,\beta) \quad \mathrm{and}\quad  \opnorm{\Odd} \equiv (\alpha_\sDD,\beta_\sDD).
\end{align}
The ``decoupling'' reference in the name of DD is understood in terms of the coupling part: i.e., the error phase of the new channel gets reduced through this transformation.
We say noise is suppressed if the ratio $\beta_\sDD/\beta<1$, and a lower ratio would indicate better noise suppression.


A widely used indicator to characterize the performance of DD schemes is the \emph{decoupling order}. A DD scheme is said to achieve $n$th-order decoupling  if the first $n$ terms in the series (\ref{eq:Oeff Magnus series}) have vanishing coupling part:
\begin{equation}\label{dd:nth-order-condition}
\Pcp(\Omega_{\sDD}\up{k}) =0,\ \text{for } 1\le k \le n.  
\end{equation}
The decoupling order is thus a single positive integer to grade different DD schemes. Greater decoupling order is usually linked with better noise suppression rate. 
This can be seen by evaluating the norm of the Magnus series projected on to the coupling part. For an $n$th-order decoupling sequence, we have
\begin{equation}\label{eq:nth-order-alternative}
\beta_\sDD 
=\norm[\Big]{\sum_{ k=n+1}^\infty \!\!\! \Pcp(\Omega_{\sDD}\up{k}) }
\simeq (\alpha,\beta)^{n+1},
\end{equation}
where we use the notation $(\alpha,\beta)^{n+1}$ to represent a polynomial that is $(n+1)$th order in $\alpha$ and $\beta$.
Provided that the Magnus series convergences absolutely, $\beta_\sDD$ is bounded by a power series in $\norm{\Omega}$ whose leading term is on the order of $n+1$.
Therefore \Eqref{eq:nth-order-alternative} provides an alternative characterization for the $n$th-order decoupling condition, which can be useful when directly calculating the first $n$ Magnus terms is unfeasible.




\subsubsection{Error Phase}
To gauge the efficacy of DD, we need to quantify the deviation of the actual state of the quantum system, with and without DD, from the ideal, no-noise state. Following Ref.~\cite{khodjasteh2007performance}, we make use of the \emph{error phase}, which measures the strength of the system-bath interaction, the source of the noise on the system. The system and bath evolve jointly for some specified time $T$ according to the evolution operator $U(0,T)$. The underlying joint Hamilton operator generating the dynamics can be time-dependent, and can include---or not---the DD pulses on the system. We write $U(0,T)\equiv \upe^{-\upi T\Heff}$, for some effective time-independent system-bath Hamilton operator $\Heff$. $\Heff$ can be split into two pieces: $\Heff\equiv \HeffB+\HeffSB$, where $\HeffB\equiv \frac{I_\mathrm{S}}{d_\mathrm{S}}\otimes\tr_S(\Heff)$ acts on the bath alone, while $\HeffSB\equiv \Heff-\HeffB$ contains all the pieces that act nontrivially on the system. $\HeffSB$ can be thought of as the effective system-bath interaction over this time $T$. We define the error phase as the norm of that interaction, multiplied by the time interval,
\begin{equation}\label{eq:ErrorPhase}
\ep\equiv \Vert T \HeffSB\Vert .
\end{equation}
We use a norm such that $\Vert S\otimes B\Vert = \Vert S\Vert \Vert B\Vert$, and $\Vert I\Vert =1=\Vert X\Vert = \Vert Y \Vert =\Vert Z\Vert$ for single-qubit $I, X, Y$, and $Z$.

As we will see, the norm of $\HeffB$ will also enter our analysis. We define the corresponding error phase for the bath-only term as $\epB\equiv \Vert T\HeffB\Vert $, and also ``two-component" error phase as
\begin{equation}
\Phi\equiv \opnorm{T \Heff}\equiv (\epB,\ep)
\end{equation}
\blue{(To merge with new text.) }\gray{
Following the properties of operator norm, thus-defined map is  absolutely-scalable $\opnorm{a\, \Omega}= |a|\cdot \opnorm{\Omega}, \forall a \in \mathbb{C}$,
and satisfies the inequality, 
$\opnorm{A+B}\le \opnorm{A} + \opnorm{B}$,
where  the ``$\le$'' sign between number pairs  is defined by each of the components: $(a_1,b_1)\le(a_2,b_2)$ if both $a_1\le a_2$ and $b_1\le b_2$; vice versa for  the ``$\ge$'' sign. 
It can also be easily verified that the two-component norm is invariant under arbitrary disjoint unitary transformation on $\cH_\rS\otimes\cH_\rB$:
\begin{equation}
    \opnorm{(U_\rS \otimes U_\rB) \Omega (U_\rS ^\dagger \otimes U_\rB)} = \opnorm{\Omega},\, \forall U_{\rS} (U_{\rB})  \in \sU(d_{\rS(\rB)}),
\end{equation}
where $\sU(d_{\rS(\rB)})$ is set of unitary operators on $\cH_\rS$ or $\cH_\rB$.
This invariance suggests that the error phase is invariant under arbitrary interaction picture defined by a system or bath evolution.
}

\subsection{PDD}
We specialize here to the case of interest, that of the single-qubit PDD scheme. The single qubit interacts with a bath, with a joint Hamilton operator (in the absence of DD) that can be written, without loss of generality, as
\begin{equation}
H\equiv I\otimes B_I+X\otimes B_X+Y\otimes B_Y+Z\otimes B_Z,
\end{equation}
where $I$ is the identity operator on the qubit, $X,Y$, and $Z$ are the Pauli operators on the qubit, and $B_i$, for $i=I,X,Y,Z$, are operators on the bath. We identify $I\otimes B_I$ as the bath-only $H_\mathrm{B}$ and $X\otimes B_X+Y\otimes B_Y+Z\otimes B_Z$ as the interaction Hamilton operator $H_\mathrm{SB}$, and define
\begin{equation}
\opnorm{\tau H}=(\Vert\tau H_\mathrm{B}\Vert,\Vert\tau H_\mathrm{SB}\Vert)\equiv (\phi_\rB,\phi_\rSB).
\end{equation}
\red{(I moved $\tau$ inside the norm operator to conform the convention that norm should be taken on a dimensionless operator, not on Hamiltonian alone. But in the comming texts there are many violations.)}

The PDD scheme uses a simple 4-pulse sequence $ZXZX$. The corresponding $\Odd$ of Eqs.~\eqref{eq:Udd} and \eqref{eq:Oeff Magnus series}, now re-labeled as $\Opdd$, can be worked out to be
\begin{align}
\Opdd&=\Opdd^{(1)}+\Opdd^{(2)}+\ldots\\
\textrm{with}\qquad \Opdd^{(1)}&=(4\tau) I \otimes B_I \label{eq:PDDMag1}\\
\Opdd\up{2}&=-(2\tau^2)\bigl\{ X\otimes 2\upi\,[B_I,B_X]\label{eq:PDDMag2}\\
&\!\!\quad\qquad +Y \otimes {\left(\upi\,[B_I,B_Y] + \{B_X,B_Z\}\right)}\bigr\},\nonumber
\end{align}
where $[\cdot,\cdot]$ and $\{\cdot,\cdot\}$ are the commutator and anti-commutator, respectively.
$\Opdd$ should be compared against the evolution operator (over the same time period of $4\tau$) in the absence of DD: $U=\upe^{-\upi4\tau H}\equiv \upe^{-\upi\Omega}$, with
\begin{equation}
\Omega=(4\tau)H=(4\tau){\left(I\otimes B_I+\HSB\right)}
\end{equation}
Comparing $\Opdd^{(1)}$---usually the dominant term---with $\Omega$, we see that the $\HSB$ in $\Omega$ no longer appears in $\Opdd^{(1)}$ and $\Opdd^{(1)}$ is trivial on the system. This corresponds to the fact that PDD is able to remove the lowest-order noise and that it achieves first-order decoupling. \blue{(To revisit to see if a re-phrasing is needed. I'm worried about the $[B_I,B_X]$ term in $\Opdd^{(2)}$, which is of order $\Vert \HB\HSB\Vert$, not $\Vert \HSB\Vert^2$. Also the last sentence of the paragraph following Eq.~\eqref{eq:Oeff Magnus series}.)}

\red{[I am changing most of the $\Omega$-like quantities into $\tau H$s (except when we talk about the Magnus series) -- it is important to keep the time parameter visible. Sometimes, $\tau$ is the relevant time---for the no DD case---sometimes $K\tau$ is the relevant one---for the DD case. These should just be visible in the analysis, not kept hidden within $\Omega$. This becomes especially important when considering CDD.]}







\subsection{Scaling up protection}
A given DD sequence yields a given decoupling order, setting a limit on the scheme's ability to reduce noise in the system. To increase the power of the DD scheme, one can employ the method of concatenation introduced in Ref.~\cite{khodjasteh2005fault}. In that work, concatenated DD (CDD) was built upon the basic PDD scheme; the same procedure of concatenation, however, can be applied to other basic DD sequences. The idea is to make use of concatenation to increase the decoupling order of the resulting DD sequence, hence scaling up the protection of the system against noise.

CDD can be described in a recursive manner. We begin with the bare evolution, without any DD sequence, writing the evolution operator over some time interval $t$ as
\begin{equation}
U_0(t)\equiv \upe^{-\upi t H_0},
\end{equation}
where $H_0\equiv H$, with the subscript $0$ added here in preparation for concatenation to higher levels. With a DD scheme of $L$ pulses, applied at time intervals (assuming regular-interval DD) $\tau_0$, the evolution operator is
\begin{equation}
U_1(\tau_1)\equiv P_LU_0(\tau_0)\ldots P_2U_0(\tau_0)P_1U_0(\tau_0),
\end{equation}
where $\tau_1\equiv L\tau_0$. The subscript $1$ is to be understood as indicating that this is concatenation level 1. To concatenate further, $U_k(\tau_k)$ is defined recursively, 
\begin{equation}
U_{k+1}(\tau_{k+1})\equiv P_LU_k(\tau_k)\ldots P_2U_k(\tau_k)P_1U_k(\tau_k),
\end{equation}
increasing the concatenation level by 1 each time, and with $\tau_{k+1}\equiv L\tau_k$. With each $U_k(\tau_k)$, we associate an effective Hamilton operator $H_k$, and a dimensionless Hamilton operator $\Omega_k\equiv\tau_kH_k$, such that 
\begin{equation}
U_k(\tau_k)\equiv \upe^{-\upi\tau_k H_k}=\upe^{-\upi\Omega_k}.
\end{equation}
Each CDD scheme is determined by specifying the maximal concatenation level $n$, and either the value of $\tau_0$ or $\tau_n$. CDD at level $n$, denoted as $\CDDn$, is then a sequence of $L_n\equiv L^n$ pulses separated by time interval $\tau_0$ and taking total time $\tau_n=L^n\tau_0$ to complete.

In the remainder of the paper, we will restrict our discussion to CDD built upon the basic PDD scheme. The authors of Ref.~\cite{khodjasteh2005fault} showed that $\CDDn$ achieves $n$th order decoupling. This quantifies the benefit of scaling up the noise protection by concatenation. Appendix \ref{app:CDD} re-derives this conclusion with a different and what we believe to be clearer argument than that in the original reference. 

We can distinguish between two operational considerations: to preserve states in a quantum memory (no computational gates), or to reduce noise in the course of carrying out a quantum computation. In the memory setting, the goal is to preserve the quantum informational state for some time $T$ without damage. During this time $T$, we can do DD pulses, and ask if the noise at the end of each complete DD sequence is lower than the noise over the same time period if there were no DD pulses. In other words, for DD to work well, we require
\begin{equation}
\textrm{Memory setting:}\quad \epsilon_\mathrm{DD}<\epsilon(L),
\end{equation}
where $\epsilon_\mathrm{DD}$ quantifies the noise after the DD sequence, while $\epsilon(L)$ is the noise after bare evolution for the time taken for the $L$ DD pulses to be applied.
In the computational setting, the comparison of with and without DD is different. With DD, computational gates can only be applied at the completion of each iteration of the DD sequence, as opposed to every time step without DD. The condition for DD to be effective in this case is then
\begin{equation}\label{eq:cond}
\textrm{Computational setting:}\quad\epsilon_\mathrm{DD}<\epsilon(1),
\end{equation}
where $\epsilon(1)$ is the noise after bare evolution for a single time step. 

\begin{figure}[htbp]
 \centering
 \includegraphics[width=\linewidth]{memory-vs-computation}
 \caption{\blue{An illustration of the CDD time evolution maps under increasing concatenation levels.  We compare the quantum memory setting (above) to the quantum computation setting (under).}}
 \label{fig:memvscom}
\end{figure}

\blue{These two perspectives result in very different overall decoupling strategies. Especially if one is using CDD to ``scale up protection''. As illustrated in Fig.~\ref{fig:memvscom}, for the quantum memory setting, as total time is fixed $T$, one only need to come up with finer and finer slicing of the time evolution pieces; but for the quantum computation setting, one need to join the DD control gates to form a dilated time evolution map. The past papers in favor of CDD had taken the former perspective. It is undeniable that with finer and finer slicing of time evolution, one gets better and better performance. But this picture has some series drawbacks. First the total evolution time $T$ is typically unknown, even for quantum memory. Hence there is no way of knowing in advance which gate to perform at what time. Second, there exists a minimal switch/cool-down time between consecutive gates due to 
technological limitations. Hence it is impractical to arbitrarily suppress noise by increasing concatenation level. 
} 

In our work, we focus on the computational setting, the more stringent one among the two, though it is straightforward to modify our analysis for the memory case. As we will see, Condition \eqref{eq:cond} will yield a requirement on the noise parameters characterizing the noise in the system and the DD pulses. We refer to that requirement as the ``break-even point" for DD, borrowing terminology from quantum error correction and fault-tolerant quantum computing.\red{ (There was a comment in the .tex file that some past papers have analyzed the memory case. What are those papers? Do you just mean the Khodjasteh-Lidar 2007 paper? That paper looks only at imperfections due to finite-width pulses, not control errors as we do here. Their paper hence only has a single-parameter $\ep$, not our two-parameter $\ep$ and $\eta$ situation. In fact, in current experiments $\eta$ is likely the larger problem; memory noise is usually much smaller than gate noise. Or are there other earlier papers?)} \blue{(Yes, that paper in particular. Their conclusion that CDD decouples to order $n$ and dramatically outperforms PDD come from this perspective. Our paper is focused on the quantum computation case which is more practical. See my new added picture \ref{fig:memvscom}). And let me quote their words (bottom left page 10) on how they do the comparison: ``The higher order data for PDD are obtained by simply repeating the basic sequence and shrinking the pulse interval. This is necessary to get the long-term behavior of decoupling. \ldots''  I move this memory/computation argument from the previous  section as it is more appropriate when we discuss the scaling behavior.  ---Jiaan)}

\blue{(To be merged with the new text.) }\gray{The conditions for achieving noise suppression are already derived previously for the idealistic PDD and CDD case.
In general, we find that smaller $(\alpha,\beta)$ values would lead to to better noise suppression rate. Therefore the gates should be performed as frequently as possible. But this may leads to suboptimal outcomes in practice given the extra noise introduced by imperfect gate operations. To study the fault-tolerance of DD, we must account for the additional noise associated with the control gates.}


%%%%%%%%%


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limits of decoupling -- The break-even conditions}
Now we have introduced the basic principles of DD, a natural question will be 
how 


Any noise mitigation strategy is effective only if its costs---the increased complexity of carrying out the quantum computational task---are lower than its benefits---the increased ability to remove adverse effects of the noise. The costs enter not just because any noise mitigation approach requires the use of more resources, e.g., more gates, more qubits, etc., but more that those added resources are themselves imperfect in practice, such that the unmitigated noise of the resulting larger system is unavoidably larger than if no noise mitigation strategy was adopted. There is then a net benefit only if the added noise is low enough to not overwhelm the added noise-removal capabilities. Such is the content of any fault-tolerant analysis, usually applied to quantum computing tasks protected by quantum error correction. Here, we apply the same logic to DD, and ask when the added benefit of averaging away part of the noise outweighs the added cost of having to do additional DD pulses.




%%%%%%%%%
\subsection{Ideal case}

Let us first discuss when ideal PDD is useful---we expect to recover the usual statement of when the idea of PDD works at all. We choose the error phase as our figure of merit: $\epsilon\equiv \Phi$. For PDD to be useful, we require, under the computational setting, 
\begin{equation}
\ep\leq \phi_\rSB.
\end{equation}
From our earlier discussion of PDD, it is clear that $\ep=\Vert \Opdd^{(2)}+\Opdd^{(3)}+\ldots\Vert$. The full Magnus series is difficult to write down, but we can employ the dominant term, $\Opdd^{(2)}$ which acts nontrivially on the system, for the approximate condition:
\begin{equation}\label{eq:cond1}
\ep\simeq\Vert \Opdd^{(2)}\Vert\leq \phi_\rSB.
\end{equation}
Using the expression for $\Opdd^{(2)}$ from Eq.~\eqref{eq:PDD-magnus-2}, we have
\begin{align}
\Vert\Opdd^{(2)}\Vert&\leq 2\tau^2{\bigl(2\Vert[B_I,B_x]\Vert+\Vert[B_I,B_Y]\Vert +\Vert\{B_X,B_Z\}\Vert\bigr)}\nonumber\\
&\leq 4\phi_\rB\tau\bigl(2\Vert B_X\Vert +\Vert B_Y\Vert\bigr) +4\tau^2\Vert B_X\Vert\Vert B_Z\Vert\nonumber\\
&\leq 12\phi_\rB\phi_\rSB+4\phi_\rSB^2\label{eq:Opdd2}
\end{align}
noting that $\phi_\rB\equiv \tau\Vert H_\mathrm{B}\Vert =\tau\Vert B_I\Vert$, and that $\phi_\rSB\equiv \tau\Vert H_\mathrm{SB}\Vert=\tau{\left[\sum_{i=X,Y,Z}\Vert B_i\Vert^2\right]}^{1/2}\geq \tau\Vert B_i\Vert$ for any $i=X,Y,Z$ \blue{(The first equality is true under the H-S induced norm, but missing a factor of 2, as written; can be remedied by using normalized Pauli operators. Need to fix this throughout the paper)}.
To get condition \eqref{eq:cond1}, it then suffices to require
\begin{equation}
12\phi_\rB+4\phi_\rSB\leq1.
\end{equation}

This amounts to a requirement that both $\phi_\rSB$ and $\phi_\rB$ be small for PDD to work well. That $\phi_\rSB$ has to be small comes as no surprise---$\phi_\rSB$ quantifies the strength of the noise on the system, and DD is expected to work well as long as the noise is weak enough so that the remnant noise is weak. The requirement that $\phi_\rB$ be small is perhaps a bit more surprising -- after all, it bounds the bath-only term which does not directly lead to noise on the system Nevertheless, $H_\mathrm{B}$ determines the evolution rate of the bath. The requirement that $\phi_\rB$ also has to be small should be understood as the requirement that any DD scheme requires the noise to remain more or less constant throughout the sequence, for good averaging by the pulses. $\phi_\rB$ quantifies how rapidly the bath evolves, and hence how quickly the noise seen by the system changes (through the evolution of the bath operators $B_i$ in the Heisenberg picture). A slowly evolving noise requires then a small $\phi_\rB$. Tracing back to the original calculation, we see that part of the pre-factor of 12 of $\phi_\rB$ is the ``4" for the length of the PDD sequence; a longer sequence will have a larger pre-factor and hence a more stringent requirement that $\phi_\rB$ is small, consistent with our interpretation here and our standard understanding of DD.

\blue{(To be edited and merged with the new text.) }
%We note the following inequalities:
%\begin{align}\label{eq:errph-strict}
%    \max_{i\in\{1,2,3\}} \norm{B_i}\le \norm[\Big]{\sum_{i=1}^3 \sigma_i \otimes B_i} \le \sum_{i=1}^3 \norm{B_i}.
%\end{align}
%The proof is given in Appendix~\ref{app:norm-ineq}. We use these bounds to derive a ``strict condition''. first, 
%\begin{align}
%\norm{\Opdd\up{2}(\Omega)} &\le
%4\norm{[B_0,B_1]} +2\norm{\upi [B_0,B_2] +\{B_1,B_3\}} \notag \\
%&\le 8 \alpha \norm{B_1} + 4 \alpha \norm{B_2} + 4\norm{B_1}\norm{B_3} \notag\\
%&\le 12\alpha\beta +4\beta^2,
%\end{align}
%we then bound the last line by $\beta$ to arrive at: 
%\begin{equation}\label{eq:pdd-region-strict}
%    12\alpha + 4\beta \le 1.
%\end{equation}
\gray{On the other hand, the inequalities (\ref{eq:errph-strict}) 
inspires use to use the following approximation for the error phase: 
\red{(The following is exactly true, not just approximately so, up to these factors of 2 that can be fixed -- but don't matter for the final inequality for the threshold condition -- for the Hilbert-Schmidt (H-S) induced norm. What is the norm used in producing Fig.~\ref{fig:pdd-region}? If that was the H-S norm, that would explain why this version of the inequality works well.)}
\blue{(That is the infinite norm, i.e., the largest eigenvalue, and consistently used across the orginal script. The reason was explaned in the origional error phase section. Basically the norm need to satisty $\norm{I}=1$ for whatever dimensionality of the identity.  This is necessary for attaching an ancilla system without changing the error phase.---Jiaan)}
\begin{equation}\label{eq:errph-approx}
    \norm[\Big]{\sum_{i=1}^3 \sigma_i \otimes B_i} \approx \sqrt{\sum_{i=1}^3 \norm{B_i}^2}.
\end{equation}
Such approximation is valid up to a factor $\in[1/\sqrt{3},\sqrt{3}]$.
This approximation allows us to derive an ``approximate condition''. 
We estimate
\begin{align}\label{eq:beta2-pdd-estimate}
\beta_\mathsf{PDD}^2 & \approx
\norm{-4\upi  [B_0,B_1]}^2 +\norm{-2\upi  [B_0,B_2] - 2 \{B_1,B_3\}}^2 \notag \\
&\le (8\alpha \norm{B_1})^2 + (4\alpha\norm{B_2} + 4\norm{B_1}\norm{B_3})^2,
\end{align}
Defining $x_i\equiv\norm{B_i}/\beta$, then upper-bounding the r.h.s.\  by $\beta^2$ requires
\begin{equation}\label{eq:PDD-optimization}
\max_{\mathclap{x_1^2+x_2^2+x_3^2=1}} \  (2 \alpha x_1)^2 + (\alpha x_2 + \beta x_1 x_3)^2\le \frac{1}{16}.
\end{equation} 
Solution of this constrained optimization problem leads to:
\begin{equation}\label{eq:pdd-region}
\begin{aligned}
\Bigl(\frac{\beta}{\sqrt{3}}\le \alpha \le \frac{1}{8} \Bigr)
\ \mathrm{or}\ \Bigl(10 \alpha ^2+\frac{9 \alpha ^4}{\beta ^2}+\beta ^2\leq \frac{1}{4}\Bigr). 
\end{aligned}   
\end{equation}
This set of inequalities automatically implies (\ref{eq:pdd-region-strict}),
it gives a tighter but less strict condition due to the approximation used
for the error phase.


The criteria (\ref{eq:pdd-region-strict}) and (\ref{eq:pdd-region}) each determines a region in the $(\alpha,\beta)$ parameter space where noise suppressing is achieved using the leading order Magnus term. 
But in order for the calculations to make sense, we have assumed that the Magnus series converge absolutely. According to (\ref{dd:Magnus-abs-converge}), the necessary condition here is $4 \norm{\Omega}_\infty   < \xi$.
Since $\norm{\Omega} \le \alpha +\beta$, we may use 
a more stringent convergence bound:
\begin{equation}\label{dd:PDD-magnus-abs}
    \alpha +\beta \le \frac{1}{4}.
\end{equation}

To examine the accuracy of the two theoretical bounds, we perform numeric tests as a verification. We first randomly generate  four $2\times 2$ Hermitian matrices for the bath operators satisfying the normalization condition in \Eqref{eq:bathops-norm}, then simulate the PDD protocol and use matrix logarithm to find the actual $\Opdd$ and error phase $\beta_\mathsf{PDD}$.  For each fixed $(\alpha,\beta)$ point, we numerically maximize the error phase reduction ratio $\beta_\mathsf{PDD}/\beta$ over 1000 random instances. The result is presented in \Figref{fig:pdd-region}, where a point in blue color represents a greater-than-one ratio and  yellow color represents smaller-than-one ratio. Thus the graph reflects the true noise suppressing condition by the continuous yellow-colored region.
We also plot the boundaries for the two theoretical noise suppression region from (\ref{eq:pdd-region-strict}) and (\ref{eq:pdd-region}), together with the absolute convergence region (\ref{dd:PDD-magnus-abs}) for comparison. 

\begin{figure}
\includegraphics[width=0.8\linewidth]{pdd-ideal-region}
\caption{The noise reduction ratio $\beta_\sDD/\beta$ obtained through maximization over random bath operators plotted in the $(\alpha,\beta)$ parameter plane. In comparison, the theoretical boundaries for noise reduction are also plotted, with dotted red line for (\ref{eq:pdd-region-strict}) and solid red line for (\ref{eq:pdd-region}), also with the boundary for the absolute-convergence condition (\ref{dd:PDD-magnus-abs}) in dashed green line. Note the ranges for $\alpha$ and $\beta$ are chosen differently for better visual effect.}
\label{fig:pdd-region}
\end{figure}

As long as the two-component norm of the free evolution Hamiltonian falls in the yellow region on the lower-left corner, the idealist PDD scheme is guaranteed to work, in the sense of reducing the error phase. This reflects the fundamental ``small noise'' assumption of DD. From the numerical results, we learn that the bound by the ``strict condition'' from (\ref{eq:pdd-region-strict}) is too loose compared with the ``approximate condition'' (\ref{eq:pdd-region}), which works surprisingly well in reflecting the true boundary of the noise-reduction region. The faithfulness of the latter bound is particularly striking considering the points beyond the absolute-convergence boundary (above the green dotted line), where our derivation should be unreliable in principle. An explanation is that the absolute-convergence criteria (\ref{dd:PDD-magnus-abs}), sufficient but not necessary, is a loose one and the leading order Magnus series works well beyond the region predicted by this inequality. This piece of evidence boosts our confidence in using the leading order Magnus term as approximation in the following parts of this work. 
}



%%%%%%%%%
\subsection{Noisy gates}
Previously, we treated the DD control gates in an ideal manner, which implies instantaneous and noise-free pulses. In practice, of course, the control gates are neither instantaneous nor noise-free. Hence the analysis for ideal DD cannot be directly carried out.

The effects of quantum noise on the system can be generally modelled with CPTP channels, which need not be unitary. The introduction of non-unitarity is problematic as the error phase, which is used to study the efficacy of DD, can no longer be defined.
However, one may include some ancillary qubits to transform any quantum channel into a unitary evolution over the extended Hilbert space. For the analytical treatment below, we will always assume this dilation for the noisy gates. Hence, we can ascribe Hamiltonian generators for the noisy control gates. 
Such generator can be time-dependent and involves in the term necessary for the control in addition to various sources contributing to the noise. 
Focusing on the $i$th gate-interval,  we can write the total Hamiltonian:
\begin{equation}\label{eq:noisy-Hamiltonian}
 H(t) = H_e + H_c(t), \quad t_{i-1}< t \le t_i,
\end{equation}
where $H_e=H_\rB+H_\rSB$ is the error Hamiltonian between system and bath, $H_c(t)$ is the control Hamiltonian generating the gate $P_i$.
For the ideal case considered earlier, it is assumed $H_c(t) \propto \delta(t-t_i)$; then the corresponding time evolution operator is simply $P_i \upe^{-\upi \tau H_e} =P_i \upe^{-\upi \Omega}$. For the case of noisy gates, the control Hamiltonian $H_c(t)$ is not a delta spike and will only approximately generate the gate $P_i$.

In general, directly solving the DD time evolution operator $U(t_L,t_0)$ from $H(t)$ in \Eqref{eq:noisy-Hamiltonian} will not work, as the very large $H_c(t)$ integral in the matrix exponent will break the convergence condition for the Magnus series. Hence it is necessary to separate out the ``pure gate'' parts from the ``free evolution'' parts. We formally perform such separation  by  expressing the solution to unitary time evolution for the $i$th gate interval as:
\begin{equation}\label{eq:noisy-gate-formal}
 \wt U(t_i,t_{i-1})
 = P_i \upe^{-\upi \wt O_i}, 
\end{equation}
where the gate-dependent $\wt O_i$ replaces the free evolution generator $\Omega$ for ideal DD. 
We put tildes over operators to signify that the DD control gates are noisy. 
Similar to the ideal DD case, we can split the $P_i$s by defining $P_i=G_{i+1}^\dagger G_{i}$ and then,
\begin{equation}
\begin{aligned}
  \wt U_\rDD= \upe^{-\upi  G_L \wt{\Omega}_L  G_L^\dagger} \ldots
  \upe^{-\upi G_2 \wt{\Omega}_2  G_2^\dagger} \upe^{-\upi G_1\wt{\Omega}_1G_1}\equiv\upe^{-\upi\wt{\Omega}_\rDD} .
\end{aligned}
\end{equation}
Provided the noise being small, the $\wt{\Omega}_i$s are small and we may use the Magnus formula to derive the leading order Magnus series as good approximation to $\wt{\Omega}_\rDD$.
The overall goal is to figure out the conditions such that the noise-inflicted DD error phase $\wtep \equiv \norm{\wt{\Omega}_{\rDD,\rSB}}$  is still reduced compared to the bare Hamiltonian error phase $\phi_\rSB = \norm{\Omega_{\rSB}}$. For simplicity, let us employ a single parameter $\eta$, which is defined later,  to quantify the noise strength associated with the gates.  The break-even condition is, in essence, to invert the inequality
\begin{equation}
 \wtep(\phi_\rB,\phi_\rSB,\eta) < \phi_\rSB,
\end{equation} 
and obtain an upper bound on the noise level $\eta<\eta_{\rmax}(\phi_\rB, \phi_\rSB)$.
To achieve this, we not only need an appropriate noise strength parameter $\eta$, but also correctly estimate the DD error phase function $\wtep(\phi_\rB,\phi_\rSB,\eta)$.  

 In the followings, we will mainly focus on the PDD to derive explicit break even conditions for various noise. But our analysis should be easily generalized to other DD sequences as well.







\subsubsection{Noisy pulses}
If the non-zero duration of $H_c(t)$ is much shorter than the gate interval,  the control gates can still be viewed as instantaneous pulses. In this section we consider noisy pulses, that is 
$H_c(t)\sim \delta(t-t_i)$, but does not produce the ideal gate.
The  time evolution operator for the $i$th gate interval becomes:
\begin{equation}\label{eq:npulses-Ui}
 \wt{U}(t_i,t_{i-1}) = \wt{P}_i \upe^{-\upi \Omega},
\end{equation}
where $\widetilde{P}_i$ is the noisy pulse version for the ideal $P_i$ gate and $\Omega=\tau H_e$ is the free evolution generator.
Let us also associate to $\wt{P}_i$ a Hermitian generator, which should be dominated by that of an ideal gate in addition to a small noise part:
\begin{equation}\label{eq:npulses-Pi}
 \widetilde{P}_i= \exp\left[ -\upi \left( \Omega_{P_i} +  \eta \Gamma_{P_i} \right)  \right],
\end{equation}
where $\Omega_{P_i}$ is responsible for the ideal gate $P_i = \exp(-\upi \Omega_{P_i})$ and supported only on the system; and $ \eta \Gamma_{P_i} $ is responsible for the noise and supported on the system-bath-ancilla composite in general. We have introduced the explicit small parameter $\eta$ to facilitate order tracking and normalized $\Gamma_{P_i}$. For PDD in particular, the sequence comprises only $X$ and $Z$ gates. 
And we may write the noisy $X$ and $Z$ pulses as:
\begin{equation}
\widetilde{X} = \upe^{-\upi ( \frac{\pi}{2} \sigma_1 + \eta\Gamma')},\quad
 \widetilde{Z} = \upe^{-\upi ( \frac{\pi}{2} \sigma_3 + \eta\Gamma'')},
\end{equation}
where $\Gamma'$ and $\Gamma''$ accounts for the noise in $\wt X$ and $\wt Z$.
We separate out the system part of these operators by $\Gamma' = \sum_i \sigma_i \otimes B'_i $ and $\Gamma''=\sum_i \sigma_i \otimes B''_i$, with normalized operators $B'_i$ and $B''_i$ acting on the bath-ancilla product space. 
The time evolution for the noisy PDD sequence then becomes
\begin{equation}\label{eq:UPDD-gatedep}
 \begin{aligned}
\wt{U}_\rDD &=
 \widetilde{Z} \upe^{-\upi \Omega}
 \widetilde{X} \upe^{-\upi \Omega}
 \widetilde{Z} \upe^{-\upi \Omega}
 \widetilde{X} \upe^{-\upi \Omega}\\
 & = \upe^{-\upi  \Gamma_3} \upe^{- \upi\Omega_3}
 \upe^{-\upi  \Gamma_2}  \upe^{-\upi\Omega_2}
\upe^{-\upi  \Gamma_1} \upe^{-\upi\Omega_1}
\upe^{-\upi  \Gamma_0}  \upe^{-\upi \Omega_0},
\end{aligned}
\end{equation}
where $\Omega_i \equiv \sigma_i \Omega \sigma_i$ as in the ideal case; additionally we introduce
$\upe^{-\upi  \Gamma_3}\equiv \wt Z Z$,
$\upe^{-\upi  \Gamma_2}\equiv Z \wt X Y$,
$\upe^{-\upi  \Gamma_1}\equiv Y \wt Z X$, and 
$\upe^{-\upi  \Gamma_0}\equiv X \wt X$.
By keeping the first order in 
$\eta$, we can derive
\begin{equation}\label{eq:PDDnp-Gamma}
 \begin{aligned}
 \Gamma_3 &= \eta(\sigma_0 \otimes B_0''- \frac{2}{\pi} \sigma_1 \otimes B_2'' 
  +\frac{2}{\pi}  \sigma_2 \otimes B_1'' + \sigma_3 \otimes B_3''),\\
\Gamma_2 &= \eta(\sigma_0 \otimes B_0'- \sigma_1 \otimes B_1'
  +\frac{2}{\pi}  \sigma_2 \otimes B_3' + \frac{2}{\pi} \sigma_3 \otimes B_2'),\\
  \Gamma_1 &= \eta(\sigma_0 \otimes B_0''+ \frac{2}{\pi} \sigma_1 \otimes B_2'' 
  +\frac{2}{\pi}  \sigma_2 \otimes B_1'' - \sigma_3 \otimes B_3''),\\
 \Gamma_0 &= \eta(\sigma_0 \otimes B_0'+ \sigma_1 \otimes B_1'
  +\frac{2}{\pi}  \sigma_2 \otimes B_3' - \frac{2}{\pi} \sigma_3 \otimes B_2').
 \end{aligned}
\end{equation}
\blue{Readers may refer to Appendix~\!\ref{app:PDDnpDerivation} for derivations of the above results.}


Every term on the exponent in \Eqref{eq:UPDD-gatedep}  is now at least linear in the smallness $\eta$ or $\norm{\Omega}$ and we can invoke the Magnus formula to calculate $\widetilde\Omega_\mathrm{PDD}$. 
The first order term suggests:
\begin{equation}\label{eq:PDDnp-firstorder}
 \wt\Omega_\rDD\up{1}= \sigma_0 \otimes (4B_0 + 2\eta( B'_0 + B''_0)) 
+ \sigma_2 \otimes \frac{4}{\pi}\eta(B_1''+B_3').
\end{equation}
When the gate noise strength $\eta$ is at least of similar size as the environmental noise $\phi_\rSB$---the gate noise is typically stronger than the background noise in many experiments---the first order Magnus term would be of leading order in the Magnus series. And the error phase after PDD is reduced to a linear multiple in $\eta$. 
 we upper-bound the size of the first order coupling by:
\begin{equation}
 \wt\Phi_\rSB \approx \norm{ \frac{4\eta}{\pi}(B_1''+B_3')} \le \frac{8}{\pi}\eta.
\end{equation}
This results in the first order breakeven condition:
\begin{equation}
 \eta \le \frac{\pi}{8} \phi_\rSB.
\end{equation}
This condition indicates that in order to achieve noise suppression, the gate noise should be bounded by a fraction of the free evolution noise. If any observable improvement from DD is expected, the pulses must be very accurate in the first place.   On the other hand if $\eta\ll \phi_\rSB$, the existence of pulse noise contributes negligibly and the second oder term will be similar to the ideal PDD case. Hence to faithfully approximate $\wt\Omega_\rDD$
in all possible arrangements, we may keep every term that is linear in $\eta$ and up to second order in the smallness $\phi_\rB$ or $\phi_\rSB$ (alternatively: second order in $\phi$). Focusing on the interaction part, the result becomes:
\begin{equation}
 \wt\Omega_{\rDD:\rSB} = \Omega_{\rDD:\rSB} +\sigma_2 \otimes \frac{4}{\pi}\eta(B_1''+B_3') + \cO(\eta\phi,\eta^2).
\end{equation}
Bounding the resulting error phase and applying triangular inequality, we have the second order breakeven condition:
\begin{equation}\label{eq:npulses-breakeven2}
   \eta \le \frac{\pi}{8} \phi_\rSB - \frac{\pi}{8}\Phi_\rSB^{(\mathrm{ub})}.
\end{equation}
We remark that this is a loose bound and tighter bound can be obtained by performing optimization on $\norm{\wt\Omega_{\rDD:\rSB}}$ akin to what we did for the ideal case, rather than using triangular inequality. But the current form is enough to serve our purpose. 
For verification, we numerically simulated PDD with noisy pulses and compare the results with our our break even conditions. The results are shown in \Figref{fig:pdd-noisy-pulse}. 
To generate the diagrams, for each fixed tuple of parameters $(\phi_\rB,\phi_\rSB,\eta)$, we randomly generate 300 sets of the Hermitian matrices $\{\Omega,\Gamma',\Gamma''\}$ over a uniform distribution 
satisfying the given parameters. Noisy PDD is simulated to obtain the noise reduction ratio $\wt\Phi_\rSB/\phi_\rSB$ for each particular set of $\{\Omega,\Gamma',\Gamma''\}$ as inputs. The maximal noise reduction value, which should reflect the worst case performance, is recorded for each fixed $(\phi_\rB,\phi_\rSB,\eta)$ parameter. 
The effects of noisy gates are visualized from two aspects: the shrinking of the noise removal region in the $(\phi_\rB,\phi_\rSB)$ diagram compared to the ideal case (\Figref{fig:pdd-noisy-pulse1}); and the relation between the maximally tolerable gate noise strength versus the environmental noise strength
 (\Figref{fig:pdd-noisy-pulse2}). From the figures we can see that our first order condition works well as long as the noise parameter $(\phi_\rB,\phi_\rSB)$ is weak and the second order condition is applicable even when the noise strength parameters are not necessarily small.



 \begin{figure}
 \centering
\begin{subfigure}{0.9\linewidth}
\includegraphics[width=\linewidth]{pdd-noisypulse1}
\caption{Fixed gate noise strength at $\eta =0.03$.}
\label{fig:pdd-noisy-pulse1}
\end{subfigure}
\\
\begin{subfigure}{0.9\linewidth}
\includegraphics[width=\linewidth]{pdd-noisypulse2}
\caption{Fixed environmental noise at $\phi_\rB =0.05$.}
\label{fig:pdd-noisy-pulse2}
\end{subfigure}
\caption{The noise reduction diagrams for noisy PDD with either fixed gate noise strength or environmental noise strength. The first order and second conditions derived in the main text are indicated with red solid lines and red dashed line respectively for comparison. }
\label{fig:pdd-noisy-pulse}
\end{figure}

According to \Eqref{eq:PDDnp-firstorder}, the leading order term that acts non-trivially on the system is proportional to $\eta(B_1''+B_3')$. 
As the condition $B''_1+B'_3=0$ corresponding to a zero measure set, exact first order decoupling is lost assuming no particular relation between the $X$ and $Z$ noise. 
This seems to indicate that PDD is impractical as its very usefulness lies in its ability to achieve first decoupling. 
The counterargument to the above is that the Magnus series is artificial and an non-zero 
first order term need not indicate large noise. It is more inspirational to relax upon first order decoupling and measuring noise strength in terms of the smallness parameter $\eta$.  Hence an alternative condition should be 
considered. The revised first order condition demands:
\begin{equation}
 \wt\Omega_{\rDD:\rSB}\up{1} = \cO(\eta^2).
\end{equation}
It can be shown that a sufficient condition for this is the case of ``weakly gate-dependent'' noise.
For the most generic noisy pulses, we can write introduce the gate-noise decomposition $\wt{P}_i = P_i \upe^{-\upi \eta \Gamma_i}$. The weak gate-dependence assumption is demanding that the variance in $\Gamma_i$  
is at most on the order of the smallness parameter $\eta$. Hence, 
\begin{equation}\label{eq:gateindep1}
 \wt{P}_i = P_i \upe^{-\upi \eta \Gamma + \cO(\eta^2)},\ \forall i.
\end{equation}
In other words, the dependence of the noise on the gate is of higher order. If this condition is 
 satisfied, then the time evolution readily reduces to the ideal DD case by replacing $\Omega=\tau H$ for free evolution with an effective Hamiltonian $\wt{\Omega}$ such that
\begin{equation}
\upe^{-\upi \wt{\Omega}}=\upe^{-\upi \eta \Gamma}\upe^{-\upi \Omega}.
\end{equation}
Since $\Gamma$ and $\Omega$ are both small, as required for DD to work,
one may invoke the BCH formula to get $\wt{\Omega}$ as a series of nested commutators. 
Thus obtained $\wt \Omega$ is accurate to the second order in $\eta$.
The already established map $\Omega\to \Omega_{\rDD}$ for the idea-pulse DD sequence can then be reused to estimate $\Omega_{\rDD}$.
Naturally, we recover the decoupling behavior for ideal DD. To derive the break-even condition for such weakly gate-dependent noise, 
we retain the BCH series to the second order term, and then apply triangular inequality to derive the upper bounds for $(\widetilde\phi_\rB,\widetilde{\phi}_\rSB) \equiv( \norm{\wt{\Omega}_\rB}, \norm{\wt{\Omega}_\rSB})$:
\begin{equation}\label{eq:comb-bound}
\left\{
\begin{aligned}
 \widetilde\phi_\rB &\lesssim (\eta + \phi_\rB)(1+\eta + \phi_\rSB) \equiv \widetilde\phi_\rB^{(\mathrm{ub})}\\
 \widetilde\phi_\rSB &\lesssim (\eta + \phi_\rSB) (1+\eta + \phi_\rB)\equiv \widetilde\phi_\rSB^{(\mathrm{ub})}
\end{aligned}
\right..
\end{equation}
With this, we can bound the error phase relevant for this noisy-pulse situation under the different schemes by replacing $\phi_\rB$ and $\phi_\rSB$ for the ideal case with their noisy upper bounds: 
\begin{equation}
 \widetilde\Phi_\rSB \le \Phi_\rSB(\widetilde\phi_\rB^{(\mathrm{ub})}  ,\widetilde\phi_\rSB^{(\mathrm{ub})} ) < \phi_\rSB.
\end{equation}
Further bounding the right hand side by $\phi_\rSB$ then gives us the condition for the break-even points.

The above analysis is generic and applies to all DD schemes with gate-independent noise. 
The resulting bound is general, but could be suboptimal for a specific DD scheme and a specific type of pulse imperfection. Below, we examine a concrete examples of imperfections  for PDD: 
global unitary error in the control gates,  which results in the noisy pulse 
\begin{equation}
\widetilde P_i=P_i\upe^{-\upi \bm{\theta}\cdot\bm\sigma},\ \forall i.
\end{equation}
We use the notation $\bm\sigma=(\sigma_1,\sigma_2,\sigma_3)$, and $\bm\theta\equiv (\theta_1,\theta_2,\theta_3)$ with $\theta_i$ real constants---taken as small for weak noise---that parameterize the unitary error.  This can arise from, for example, a systematic calibration error in the pulse control leading to a consistent over or under rotation. In this situation, $\Gamma\equiv \bm\theta\cdot\bm\sigma$ acts only on the system and does not have a pure bath term. In the appendix, we derive an tighter bound:
\begin{equation}\label{eq:eff-Hami-tcp}
\left\{
\begin{aligned}
\widetilde{\phi}_\rB &\le \phi_\rB + \frac{1}{3}\theta  \phi^2_\rSB  \\
\widetilde{\phi}_\rSB &\le \phi_\rSB +  \theta^2  \phi_\rSB  \\
\end{aligned}    \right.,
\end{equation}
where $\theta \equiv \norm{\bm \theta}$ is the rotation angle associated with the gate error.
Assuming the noise to be small, we may only use the leading order 
approximation, which is by itself accurate to the second order. 
Substituting the upper bounds to  $\Phi_\rSB(\wt\phi_\rB,\wt\phi_\rSB)$ and keeping the leading order terms,  we can predict the following simplified bound for PDD:
\begin{equation}\label{eq:npdd-bound-simple}
2\phi_\rB^2 + \frac{(\theta+\phi_\rSB)^4}{4\phi_\rSB^2}\le \frac{1}{16},
\end{equation}
From this inequality, the globally maximally allowed $\theta$ can be found at $\phi_\rB=0$, $\phi_\rSB=1/8$ with
$\theta_\mathrm{max}= 1/8$. Furthermore, we can solve for $\theta$ in terms of $\phi_\rB$ and $\phi_\rSB$ to arrive at the noise threshold for the rotation angle:
\begin{equation}\label{eq:npdd-err-thres}
    \theta \le (1-32\phi_\rB ^2)^{\frac{1}{4}} \sqrt{\frac{\phi_\rSB}{2} }-\phi_\rSB
    \quad \lesssim \sqrt{\frac{\phi_\rSB}{2}}.
\end{equation}
It states that for the regime where the the free evolution noise is small, gate noise should at most be on the order of the square root of the free evolution noise. This  is quite different from the generic noise case where the upper bound dependence in $\phi_\rSB$ is linear. 


\subsubsection{Control signals of finite strength}
In reality the control signals have finite strength hence non-zero durations.
This deviation from the delta function contributes to an extra source of noise, which adds to the already existing gate control error. 
 In this section, we consider such source of noise. 


The simplest example is that of the rectangular signals. Assuming the pulse duration is $\tau_p$, the Hamiltonian  for the $i$th gate interval is split into two constant pieces: $H=H_e+H_c$ for $t_i -\tau_p  < t \le t_{i}$ under external control, and $H=H_e$ when control is off. The control Hamiltonian is assumed to satisfy $P_i = \upe^{-\upi \tau_p H_c }$.
Such noise model was considered in the original CDD paper~\!\cite{khodjasteh2007performance}. 
Here we work out a slightly more involved model, where apart from the finite width, the control Hamiltonian is also infested with a small control error denoted by $\epsilon\Gamma_i$, with $\max{(\Gamma_i)}=1, \forall i$ and $\epsilon\ll 1$.  Namely, without the environment noise, the $i$th control gate
is $ \upe^{-\upi (\Omega_{P_i} +\epsilon \Gamma_i)}$, where $\upe^{-\upi \Omega_{P_i} }$ is the ideal gate. 
We write solution to the time-evolution operator as:
\begin{equation}
 \wt U(t_{i},t_{i-1}) =  \upe^{-\upi (\Omega_{P_i} +\epsilon \Gamma_i+
 (\tau_p/\tau) \Omega)}  \upe^{-\upi (1-(\tau_p/\tau)) \Omega}.
\end{equation}
Despite being a finite width model, one can convert such case back to the noisy pulse model.
To do so, one simply replace the free evolution generator $\Omega\to (1-(\tau_p/\tau)) \Omega$ and the pulse noise generator $\eta\Gamma$  in \Eqref{eq:npulses-Pi} with $\epsilon \Gamma_i + (\tau_p/\tau) \Omega$.
In terms of PDD, all we need to obtain the Magnus series is the substitutions $B_i \to (1-(\tau_p/\tau)) B_i$, $\eta B_i' \to (\tau_p/\tau) B_i + \epsilon B_i'$ and $\eta B_i'' \to (\tau_p/\tau) B_i + \epsilon B_i''$ in the results for noisy pulses. Using \Eqref{eq:PDDnp-firstorder} to derive the first order term, we can estimate the error phase and consequently derivative the breakeven condition as
\begin{equation}\label{eq:PDD-rect1}
\wt\Phi_{\rSB}\lesssim \frac{8}{\pi} (\frac{\tau_p}{\tau})\phi_\rSB +  \frac{8}{\pi} \epsilon\le\phi_\rSB.
\end{equation}
The ratio $\tau_p/\tau$ between the pulse width and the gate interval and is typically considered to be small. Hence the error phase contribution from the finite width is on the second order smallness if this additional smallness parameter is taken into account. In comparison,
the control error directly contributes to the first order smallness. 
This suggests DD is relatively more tolerant to the finite width error.
In the limit where gate control error is negligible, the first order breakeven condition suggests
\begin{equation}
 \tau_p/\tau \le \frac{\pi}{8}\approx 0.39,
\end{equation}
to be sufficient for noise reduction. 
This suggests that in order for DD to be useful, the control signal should be more pulse-like. Notice that this condition is derived without any control noise in mind. It puts an upper bound on how 
fast we are allowed to perform DD even with perfect control. That is, the 
control signals should be somewhat sparse and allow time for the free evolution instead of jamming together.


Extending beyond the simple rectangular signal model, we now consider a more generic situation where the control signal can be of arbitrarily shape while also accounting for the gate control error. After shifting the time origin for simplicity, the total Hamiltonian within a gate interval can be split into three parts:
\begin{equation}\label{eq:Hami-3parts}
 H(t)= H_g(t) +  H_e +  H_{ge}(t), \ 0\le t\le \tau,
\end{equation}
where $H_g(t)$ is the ``gate'' Hamiltonian, responsible for the perfect gate; 
$H_e$ is the system-bath coupling Hamilton responsible for the free evolution noise,
and $H_{ge}(t)$ is the gate error Hamiltonian responsible for the control error. It is assumed that the control signal $H_g(t)$ is pulse-like and much greater than the two noise terms when control is turned on.
We isolate the pure gate part by writing the time evolution as 
\begin{equation}
 U(\tau)=P_g \upe^{-\upi \wt \Omega_g},
\end{equation}
 where $P_g=U_g(\tau)$ is the gate unitary generated by $H_g(t)$.
The interaction picture Hamiltonian defined by
$\wt H(t)\equiv U_g^\dagger(t) (H_e + H_{ge} (t)) U_g(t)$ completes the time evolution operator $\upe^{-\upi \wt \Omega_g}$
at $t=\tau$. 
Since both $H_e(t)$ and $H_{ge}(t)$ are small, we can approximate $\wt \Omega_g$ by neglecting their higher order commutators:
\begin{equation}
 \wt \Omega_g \approx\! \int_0^\tau\!\! U_g^\dagger(t) H_e U_g(t) \dd t\, + \! \int_0^\tau\!\! U_g^\dagger(t) H_{ge}(t) U_g(t) \dd t.
\end{equation} 
We refer the first term in the above as the signal shape term and the second term as the pulse error term. 

The signal shape term is very dependent on the control signal $H_g(t)$. But anyway let us formally express the case for $X$ and $Z$ gates as:
\begin{equation}\label{eq:sigshape-formal}
\begin{aligned}
\int_0^\tau\!\! U_X^\dagger(t) H_e U_X(t) \dd t &\equiv\sigma_0 B_0
 +\sigma_1 B_1' + \sigma_2 B_2'+\sigma_3 B_3',\\
\int_0^\tau\!\! U_Z^\dagger(t) H_e U_Z(t) \dd t &\equiv\sigma_0 B_0
 +\sigma_1 B_1'' + \sigma_2 B_2''+\sigma_3 B_3'',
 \end{aligned}
\end{equation}
where we have note that the $B_0$ component is invariant
under system unitary conjugation.
To deal with the time-dependent pulse error term,  we simply bound it by
\begin{equation}
 \norm{\int_0^\tau\!\! U_g^\dagger(t) H_{ge}(t) U_g(t) \dd t} 
 \le  \int_0^\tau\!\! \norm{H_{ge}(t)} \dd t \equiv  \eta_{ge},
\end{equation}
where the small number $\eta_{ge}$ absorbs any time-dependence of the control Hamiltonian.
Hence we may effectively replace the pulse error term with a gate-dependent error map $\eta_{ge} \Gamma_g$, where $\Gamma_g$ is Hermitian and $\norm{\Gamma_g}\le 1$. For convenience, let us assume 
$\Gamma_X = \sum_i \sigma_i \otimes A'_i$ and
$\Gamma_Z = \sum_i \sigma_i \otimes A''_i$.
After substituting the expressions for the signal shape term and pulse error term into $\wt\Omega_X$ and $\wt\Omega_Z$, we are able to derive the 
effective Hamiltonian using the Magnus expansion. 
The first order term yields:
\begin{equation}
\begin{aligned}
  \wt\Omega_{\rDD}\up{1}&= 
  \sigma_0\otimes (4B_0 + 2\eta_{ge} (A_0'+A_0''))\\
 &+\sigma_2 \otimes (2(B_2' -B_2'')+2\eta_{ge}(A_2'-A_2'')).
\end{aligned}
\end{equation}
Hence, the error phase after noisy PDD can be bounded by
\begin{equation}\label{eq:nPDDeph1}
\begin{aligned}
  \wt\Phi_\rSB \lesssim 2\norm{B_2' -B_2''} + 4\eta_{ge}.
\end{aligned}
\end{equation}
For simplicity, let us assume that the gate Hamiltonian responsible for the Pauli gate $P_g$ is proportional to $\sigma_g$ but the signal strength is arbitrary:
\begin{equation}
 H_g(t) = \frac{1}{2}\omega_g(t)\sigma_g,\quad g\in\{X,Z\},
\end{equation}
where the time-dependent function $\omega_g(t)$ specifies the shape of the pulse and satisfies the condition that its time integral $\theta_g(\tau)=\pi$, with $\theta_g(t)\equiv \int_0^t \omega_g(t') \dd t'$.
Within $t=0$ and $\tau$ we have 
$U_g(t) = \cos({\theta_g(t)}/{2} ) I -\upi \sin({\theta_g(t)}/{2} )\sigma_g$.
The earlier constraint ensures that $U_g(t)$ recovers the ideal gate at $t=\tau$. 
After conjugating $H_e\tau = \sum_i \sigma_i \otimes B_i$ with $U_g(t)$,
we can write the pulse shape term as:
\begin{equation}\label{eq:pshape-term}
\begin{aligned}
&\int_0^\tau\!\! U_g^\dagger(t) H_e U_g(t) \dd t =\sigma_0 B_0  + \\
 & \left\{
 \begin{aligned}
   & \sigma_1 B_1 + 
   c_X \bigl( \sigma_2  B_2 + 
   \sigma_3 B_3 \bigr)+ 
   s_X
    \bigl(\sigma_2 B_3 - \sigma_3 B_2\bigr),\ g=X;\\
    &\sigma_3 B_3  + c_Z \bigl( \sigma_1  B_1 + 
   \sigma_2 B_2 \bigr)+ 
   s_Z
    \bigl(\sigma_1 B_2 - \sigma_2 B_1\bigr),\ g=Z,
 \end{aligned}
 \right.
\end{aligned}
\end{equation}
where the $c_g$ and $s_g$ coefficients are defined as the time averaged trig-functions:
\begin{equation}
 c_g \equiv \frac{1}{\tau}\int_0^\tau \cos(\theta_g(t)) \dd t, \ s_g \equiv \frac{1}{\tau}\int_0^\tau \sin(\theta_g(t)) \dd t.  
\end{equation}
For the ideal DD case, which assumes that $H_g(t)=\pi\delta(t-\tau)$ and  $H_{ge}(t)=0$, one can recover $\wt \Omega_X =\wt \Omega_Z = \Omega$ as excepted. 
On the other hand, if we move the pulse position to some $\tau'\in(0,\tau)$, it appears that $\wt \Omega_X \neq \wt \Omega_Z$. But the difference 
$B_2'-B_2''$ as defined in \Eqref{eq:sigshape-formal} is still zero, which is all that needed for first order decoupling. Focusing on the difference in the  $B_2$  component, 
we have 
\begin{equation}
\begin{aligned}
  \norm{B_2'-B_2''} & = \norm{(c_X-c_Z)B_2+s_X B_3 +s_Z B_1}\\
  &\le (\abs{c_X-c_Z} + \abs{s_X} + \abs{s_Z})\cdot \phi_\rSB.
\end{aligned}
\end{equation}
Here we see that the most general signal shape error is of first order smallness instead of second order for the rectangular signals. 
We also see that to reduce the signal shape error, one need to make sure that 
the control signal should have identical shapes for all gates so that $\abs{c_X-c_Z}$
is negligible; in addition the signal should be sharp to control the size of $\abs{s_g}$ terms. 

For concreteness, we use the rectangular signal, but arbitrarily placed in time to illustrate this point. Assuming the shapes for control signals are gate-independent and satisfies
\begin{equation}
 \omega_g(t)=
 \left\{
 \begin{aligned}
  &0,&& 0\le t<\tau'\\
 &\pi/\tau_p, && \tau'\le t < \tau'+\tau_p\\
 & 0,&& \tau'+\tau_p \le t\le \tau
 \end{aligned}
 \right..
\end{equation}
It is straightforward to calculate that $s_g = \frac{2\tau_p}{\pi\tau}$.
Hence the resulting error phase is independent of $\tau'$.
After substituting into \Eqref{eq:nPDDeph1}, we arrive at the breakeven condition
\begin{equation}\label{eq:PDD-rect2}
  \wt\Phi_{\rSB}\lesssim \frac{8}{\pi} (\frac{\tau_p}{\tau})\phi_\rSB +  
  4\eta_{ge}\le\phi_\rSB.
\end{equation}
This produces the same behavior compared to \Eqref{eq:PDD-rect1}, apart 
from numerical factors arisen from difference in gate error definitions. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The accuracy threshold and decoupling potential}\label{sec:threshold}
We can certainly discuss the break-even point for a particular $\CDDn$ sequence, treating it simply as a ``flattened" sequence of pulses, and ask when the error phase after $\CDDn$ is reduced:
\begin{equation}
 \Phi_{\mathrm{SB},n} < \phi_{\mathrm{SB}},
\end{equation}
 as was done for PDD in the previous section. 
However, what is more interesting is the question of the so-called accuracy threshold for CDD.
As described in the Preliminaries section, CDD achieves higher and higher decoupling order by concatenating the same basic DD scheme---PDD for our discussion here---to higher and higher levels. 
We are interested in understanding how the noise removal improves as the DD scheme scales up.  An accuracy threshold for CDD exists if the parameters governing the noise of the situation satisfying a condition $\eta<\eta_0$, such that 
\begin{equation}\label{eq:thresCond}
\Phi_{\mathrm{SB},n+1} < \Phi_{\mathrm{SB},n}\qquad\forall n=1,2,\ldots.
\end{equation}
In fault-tolerant quantum computing, there is the concept of a fault tolerance noise threshold, a strength of the noise below which scaling up the QEC code leads to improved protection against noise, and hence more accurate quantum computation. This threshold is referred to as the accuracy threshold. Here, we ask the analogous question of CDD, whether there is a condition on the noise parameter of the problem such that increasing the concatenation level always leads to improved noise removal capabilities. 
\blue{If such condition can not be satisfied, we ask the question of whether there exists an optimal concatenation level and how the imperfection in gate control could impact it.}
%

\subsection{Ideal case}
Should the accuracy threshold exist, then \Eqref{eq:thresCond} must first and foremost apply in the case where the gate noise is non-existent. 
 Below, we examine this condition for the ideal CDD before examining on the noisy version.

Following the approach of Khodjasteh and Lidar, the $\CDDn$ generator in the ideal case can be estimated as:
\begin{align}\label{eq:cdd-generator-est}
\Omega_{n} 
\approx {} & \sigma_0 \otimes 4^n B_0 \notag \\
+\ & \sigma_1 \otimes (-\upi)^{n} 2^{n(n+1)} \ad_{B_0}^{n}(B_1)\\ 
+\ & \sigma_2 \otimes (-\upi)^{n} 2^{n^2} \ad_{B_0}^{n-\!1}( \,[B_0,B_2] - \upi \{B_1,B_3\} \,). \notag
\end{align} 
It is shown in the appendix \ref{app:CDD}   that the above expression indeed captures the leading order behavior of $\Omega_{n}$. Hence $\CDDn$ indeed achieves $n$th-order decoupling. Different from the leading order term in the Magnus series, \Eqref{eq:cdd-generator-est} combines the leading order pure bath part and the interaction part. 
The pure bath part, whose size can be estimated by $\Phi_{\mathrm{B},n} \simeq 4^n\phi_\rB$, is of first order; whereas the interaction part is of $(n+1)$th order. 
Focusing on the leading order interaction part, we can derive an upper bound for for the error phase: 
\begin{equation}\label{eq:CDDerrph-ub}
\Phi_{\mathrm{SB},n} \lesssim \,
2^{n(n+2)} \phi_\rB^{n}\,\phi_\rSB \,f_n\!\Bigl(\frac{\phi_\rSB}{\phi_\rB}\Bigr),
\end{equation}
where the auxillary $f_n$ function is defined by:
\begin{equation}
 f_n(x) \equiv\left\{
 \begin{aligned}
 &1, && x \le  \sqrt{4^n-1}, \\
 &\frac{1}{2^n} \sqrt{\left(\frac{4^n-1}{2x}+\frac{x}{2}\right)^2+1}, &&
 x > \sqrt{4^n-1}.
 \end{aligned}
 \right.
\end{equation}
As mentioned in the Preliminaries section, $\CDDn$ achieves $n$th-order decoupling. This can be understood from the error phase expression: $\Phi_{\mathrm{SB},n}$ after $\CDDn$ is of order $\phi^{n+1}$, for $\phi\sim\phi_\rB, \phi_\rSB$. That $\phi_\rB$ enters the error phase should again be of no surprise---as in the PDD case, $\phi_\rB$ determines how quickly the noise seen by the system evolves, and hence affects the efficacy of DD which does a good elimination of the noise only when the noise remains nearly unchanged for the full DD sequence. 

What is perhaps more surprising is the appearance of the $2^{n(n+2)}$ factor in $\Phi_{\mathrm{SB},n}$, a important feature in the CDD. For fixed $\tau_0\equiv \tau$ as $n$ increases (e.g., if $\tau$ is the experimental limit for the switch time between consecutive pulses), such factors mean that the error phase eventually increases for large enough $n$: The exponentially decreasing $\phi^n$ factor is eventually overcome by the super-exponentially increasing $2^{n^2}$ factor. This means there is no accuracy threshold, i.e., there is no level of noise that is weak enough such that $\Phi_{\mathrm{SB},n+1}\leq\Phi_{\mathrm{SB},n}$ for all $n$. Instead, there is an maximal useful level of concatenation level, beyond which further concatenation actually increases the noise seen by the system. Fig.~\ref{fig:estimator-size} plots this situation of fixed $\tau_0$, for increasing concatenation level $n$. We observe the initial decrease of $\Phi_{\mathrm{SB},n}$ as $n$ increases, but this turns around eventually. 

\begin{figure}
    \includegraphics[width=\linewidth]{cdd-estimator}
    \caption{The error phase as a function of the concatenation level. 
    The thin colored lines are obtained from random samples satisfying $\phi_\rB=\phi_\rSB=0.001$. The blue dashed line is our theoretical upper bound for error phase. The maximal concatenation level occurs at 4 in this configuration.}
    \label{fig:estimator-size}
\end{figure}

The upper bound (\ref{eq:CDDerrph-ub}) alone is insufficient 
for predicting when will $\Phi_{\mathrm{SB},n+1} < \Phi_{\mathrm{SB},n} $. As that would require both an upper and lower bound. 
For higher concatenation level to make sense, increasing concatenation level should decrease the error phase. To derive a sufficient condition of it, we examine the recursive relation between concatenation 
levels, which suggests 
\begin{equation}\label{eq:cdd-update}
\begin{aligned}
 B_{n+1,0} &= 4  B_{n,0}\\
 B_{n+1,1} & = -4\upi [B_{n,0}, B_{n,1} ]\\
 B_{n+1,2} & = -2\upi [B_{n,0}, B_{n,1} ]\\
  B_{n+1,3} &=0
\end{aligned}
\end{equation}
For both $B_1$ and $B_2$ to decrease in size, it suffice to require the map 
$-4\upi [B_{n,0},\cdot]$ a contraction map. 
By requiring its norm to be smaller than 1, we obtain the bound for the maximal concatenation level:
\begin{equation}\label{eq:cdd-max-level}
n_{\max}\le -\log_4(\phi_\rB)-3/2.
\end{equation}

Note that the existence of a maximal useful concatenation level does not technically contradict the statement that 
higher-order decoupling is achieved by higher level CDD. Using decoupling order to quantify the degree of noise removal requires, in the first place, the convergence of the Magnus series, so that the $(n+1)$th- and higher-order terms in the series are a small correction to the first $n$ terms. However, if the DD scheme is designed such that the total time for the sequence grows exponentially with $n$, as is the case for CDD if $\tau_0$ is fixed as $n$ increases, eventually, we exceed the convergence criterion and the decoupling order stops being a reasonable indicator of successful noise removal. 

We can, however, analyze a different situation: to have fixed $\tau_n\equiv T$, so that the CDD sequence takes the same amount of time, regardless of $n$. This requires $\tau_0=\frac{T}{4^n}$ for each $n$, so that the pulses are applied at shorter and shorter time intervals as the concatenation level increases. This can be the practical choice if one is doing computation where computational gates, which can only be applied at the end of a complete DD sequence in order to not interfere with the noise averaging process, have to be applied at a particular clock rate. Increasing $n$ to increase the noise removal capabilities must not increase the total time taken for the DD sequence.
Define the PDD map as $\cD$.
The evolution can be thought as 
\begin{equation}
 \Omega_{n+1} = \cD(\Omega_{n}/4).
\end{equation}
Rewrite the update rule (\ref{eq:cdd-update}) in terms of the fixed bath operators:
\begin{equation}\label{eq:cdd-update2}
\begin{aligned}
 B_{n+1,0} &= B_{n,0}\\
B_{n+1,1} & = -(1/4)\upi [B_{n,0}, B_{n,1} ]\\
 B_{n+1,2} & = -(1/8)\upi [B_{n,0}, B_{n,1} ]\\
  B_{n+1,3} &=0
\end{aligned}
\end{equation}
This leads to 
\begin{align}\label{eq:cdd-generator-est2}
\Omega_{n} 
\approx {} & \sigma_0 \otimes B_0 \notag \\
+\ & \sigma_1 \otimes (-\upi)^{n} 2^{-n^2-n} \ad_{B_0}^{n}(B_1)\\ 
+\ & \sigma_2 \otimes (-\upi)^{n} 2^{-n^2-2n} \ad_{B_0}^{n-\!1}( \,[B_0,B_2] - \upi \{B_1,B_3\} \,). \notag
\end{align} 
Apparently, $\Phi_\rB = \phi_\rB$ remains unchanged.
The error phase is reduced to
\begin{equation}
 \Phi_{\mathrm{SB},n} \lesssim \,
2^{-n^2} \phi_\rB^{n}\,\phi_\rSB \,f_n\!\Bigl(\frac{\phi_\rSB}{\phi_\rB}\Bigr).
\end{equation}
The upper bound is a super-exponentially decreasing function in $n$. This suggests that noise can be arbitrarily suppressed by increasing the concatenation level.  This requires, of course, the ability to do faster and faster pulse switching.
Eventually, of course, this becomes limited by the technological---not fundamental---constraint of how fast we can switch between pulses, and thus how short $\tau_0$ can be in an experiment.

%%%%%%%%%
\subsection{Noisy pulses}
As CDD is derived from PDD, the noisy CDD is also derived from the noisy PDD. 
Let us suppose that the noisy PDD maps the Lie algebra generator through $\wt\cD$:
\begin{equation}
 \wt\Omega_\mathsf{PDD} = \wt\cD(\Omega).
\end{equation}
For noisy $\CDDn$, since we are using the same set of noisy gates as PDD,
\begin{equation}
 \wt\Omega_{n+1}=\wt\cD (\wt\Omega_n).
\end{equation}
The threshold condition requires:
\begin{equation}
 \Phi_\rSB(\wt\cD (\wt\Omega_{n})) \le \Phi_\rSB(\wt\Omega_{n}).
\end{equation}
This is exactly the breakeven condition for noisy PDD with the free evolution generator $\Omega$ replaced by $\wt\Omega_n$.
Let us characterize the gate noise level by $\eta$,
and write the breakeven condition for PDD:
$ \eta \le \eta(\phi_\rB,\phi_\rSB)$.
The CDD threshold condition becomes 
\begin{equation}
 \eta \le \eta(\wt\Phi_{\rB,n},\wt\Phi_{\rSB,n}).
\end{equation}
Since the noise level $\eta$ on the l.h.s.\ is fixed for a given set of gates, while $\wt\Phi_{\rB,n}$ and  $\wt\Phi_{\rSB,n}$ changes with the concatenation level $n$. Hence one useful way to look at the problem is to start with an error-tolerance diagram and view the pair $(\wt\Phi_{\rB,n},\wt\Phi_{\rSB,n})$ as points evolving on the graph. Besides the graph itself, we also need to known the update rule
$(\wt\Phi_{\rB,n},\wt\Phi_{\rSB,n})\to(\wt\Phi_{\rB,n+1},\wt\Phi_{\rSB,n+1})$  for such evolution. This is, by construction of CDD, the same rule for the PDD transformation $(\phi_{\rB},\phi_{\rSB})\to(\wt\Phi_{\rB,1},\wt\Phi_{\rSB,1})$. 


\begin{figure}[htbp]
 \centering
 \includegraphics[width=\linewidth]{cddevo}
 \caption{The evolution of the $(\wt\Phi_{\rB},\wt\Phi_{\rSB})$ pair with increasing concatenation level for the ideal and noisy case.
The shaped regions are the PDD breakeven region for the 
 noiseless and noisy case respectively. }
 \label{fig:cddevo}
\end{figure}

For noisy CDD, under the computational setting, the size of the pure part 
part quadruples with every concatenation level:
\begin{equation}
 \wt\Phi_{\rB,n} \approx 4 \wt\Phi_{\rB,{n-1}}
 \approx 4^n \phi_\rB.
\end{equation} 
The evolution of the error phase is similar to that of noisy PDD:
\begin{equation}
 \begin{aligned}
 \wt\Phi_{\rSB,n} &\lesssim  8 \wt\Phi_{\rB,n-1} \wt\Phi_{\rSB,n-1}+\frac{8}{\pi}\eta,\\
&\approx (8\phi_\rB) 4^{n-1} \wt\Phi_{\rSB,n-1} + \frac{8}{\pi}\eta.\\
\end{aligned}
\end{equation}
Keeping the leading term and the final term, 


In \Figref{fig:cddevo}, we compare the noisy and ideal version of PDD.
Due to the presence of noise in the control gates, the maximal concatenation 
level reduces. The minimal error phase that can be reached by CDD increases as a result. 

For the quantum memory setting, the $\Phi_\rB$ part is constant across 
concatenation levels  and the error phase updates according to:
\begin{equation}
  \wt\Phi_{\rSB,n+1} \le \frac{1}{2}\phi_{\rB} \wt\Phi_{\rSB,n} + \frac{8}{\pi}\eta.
\end{equation}
Solving the sequence iteration rule leads to the general formula:
\begin{equation}
 \wt\Phi_{\rSB,n} \le (\phi_{\rB}/2)^n \phi_\rSB + \frac{8\eta/\pi}{1-\phi_{\rB}/2}.
\end{equation}
Provided that $\phi_{\rB}<2$ and $8\eta/\pi<\phi_\rSB(1-\phi_{\rB}/2)$,
increasing the concatenation level will decrease the noise level. 
But arbitrary noise suppression is impossible as long as $\eta\neq0$. The smallest error phase that can be obtained is proportional to the gate noise. 
\begin{figure}[htbp]
 \centering
 \includegraphics[width=\linewidth]{cddmemevo}
 \caption{The evolution of the $(\wt\Phi_{\rB},\wt\Phi_{\rSB})$ pair with increasing concatenation level for the ideal and noisy case.
The shaped regions are the PDD breakeven region for the 
 noiseless and noisy case respectively. }
 \label{fig:cddmemevo}
\end{figure}
We show in \Figref{fig:cddmemevo} the evolution of error phase under 
different levels of concatenation. Starting from a initial $\phi_\rB=\phi_\rSB=10^{-3}$, we see that while in the ideal case, the 
error phase can be exponentially suppressed, for noisy gates with $\eta=10^{-4}$, the CDD limit is quickly reached. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cross measure consistency}
\blue{(Discussions on fidelity, trace distance etc.  Compare Xiansong's results here with the theoretical predictions.)}
To capture more precisely how the error phase relate to the noise strength of a CPTP map, we establish its connection to the channel infidelity.
Such connection rely on the assumption that the noise is weak, in the sense that Hermitian operator $\Omega$ in \Eqref{eq:output-rhos} associated with the noise map is small enough.

Invoking the Baker-Hausdorff lemma \cite{rossmann2006lie}, we expand the output state in \Eqref{eq:output-rhos} as a series in the powers of $\Omega$. With a simple rearrange,
\begin{equation}\label{eq:channel-series}
(\cI-\cE)(\rhoS) 
=-\sum_{n=1}^\infty \frac{(-\upi)^n}{n!} \trB\ad_{\Omega}^n(\rhoS\otimes\rhoB),
\end{equation}
where the adjoint operator is defined by the commutator $\ad_\Omega(\placeholder)\equiv[\Omega,\placeholder]$, with $\ad^n_\Omega$ involving $n$-fold commutation with $\Omega$. According to definition \Eqref{eq:inf-def}, we can express the channel infidelity as a series as well by taking trace product with $\rhoS$ for each term in \Eqref{eq:channel-series},
\begin{equation}
\infid(\cE|\rho_\rS) \equiv  \sum_{n=1}^\infty \infid\up{n}(\cE|\rho_\rS).
\end{equation}
Since the $n$th-order term $\infid\up{n}(\cE|\rho_\rS) =\cO(\norm{\Omega}^n)$,
We can examine the leading orders in the infidelity series as an effective approximation. 

The first-order infidelity  $\infid\up{1}(\cE|\rho_\rS)$ always vanishes 
despite the form of $\Omega$, as follows from the equality:
\begin{equation}\label{eq:1st-infid}
\tr(\rhoS \trB \ad_\Omega(\rho_\rS \otimes\rho_\rB))= \tr(\rhoS[\trB (\Omega \rho_\rB),\rho_\rS])=0.
\end{equation}

To calculate the second-order infidelity, we first note a useful operator identity:
\begin{equation}\label{eq:trBad}
    \trB \ad_{\Omega_B} = 0,\quad \forall \Omega_B \in \mathfrak{h}_\rB.
\end{equation}
The proof is straightforward by applying the above operator to a generic linear operator $\sum_\alpha S_\alpha \otimes B_\alpha$ on the combined Hilbert space.
We now substitute the \Eqref{eq:omega-split} into the double commutator term $\sim\ad_{\Omega}^2$ in  \Eqref{eq:channel-series} and expand. After applying
the Jacobi identity---$\ad_{A}\ad_{B}=\ad_{B}\ad_{A}+\ad_{[A,B]}$---and invoking
\Eqref{eq:1st-infid}  and \Eqref{eq:trBad}, we have
\begin{equation}
\tr\left( \rho_\rS \trB \ad^2_{\Omega} \rho_\rS\otimes\rho_\rB\right) =  \tr\left( \rho_\rS \trB \ad^2_{\Omega_{\rSB}} \rho_\rS\otimes\rho_\rB\right).
\end{equation}
Therefore the second order infidelity $\infid\up{2}(\cE|\rho_\rS)$ does not involve in $\Omega_\rB$ and is proportional to the square of error phase $\norm{\Omega_\rB}^2$.
To bound the infidelity with the error phase, we can evaluate,
\begin{equation}\label{eq:infid2-bound}
\begin{aligned}
    0\le& \infid\up{2}(\cE|\rho_\rS) =   \frac{1}{2}  \tr\left( \rho_\rS \trB \ad^2_{\Omega_{\rSB}}(\rho_\rS\otimes\rho_\rB)\right)\\
&\le \frac{1}{2}\norm{\rhoS\otimes I_\rB}_\infty \norm{\ad^2_{\Omega_{\rSB}} (\rho_\rS\otimes\rho_\rB)}_1\\
&\le 2 \norm{\Omega_\rSB}_\infty^2 \norm{\rhoS\otimes\rhoB}_1 \le 2\norm{\Omega_\rSB}_\infty^2,
\end{aligned}   
\end{equation}
where for the upper bound we have applied the Hilbert-Schmidt inequality, the Holder's inequality and the triangular inequality for the Schatten norm class.
To show the lower bound, we first introduce the decomposition $\Omega_\rSB = \sum_{i\neq 0}\sigma_i \otimes B_i$  ($\sigma_0\equiv I_\rS$) with the generalized Pauli basis for the system, and define the correlation functions 
$\widetilde{B}_{ij} \equiv \tr(\rho_\rB B_i B_j)$ and $\widetilde{S}_{ij} \equiv \tr(\rhoS^2 \sigma_j\sigma_i) -\tr(\rhoS \sigma_i \rhoS \sigma_j)$. 
Then we have $\infid\up{2}(\cE|\rho_\rS) = \tr(\widetilde{B} \widetilde{S})$.
It can be easily verified that both $\widetilde{B}$ and $\widetilde{S}$ are positive semi-definitive matrices, therefore their trace product is nonnegative.

Furthermore, the full infidelity expression $\infid(\cE|\rho_\rS)$ can be shown to not contain any term linear in the error phase $\norm{\Omega_\rSB}$  (see appendix \ref{app:infid-beta-series}). Therefore all higher order terms are indeed smaller than the second order provided $\norm{\Omega_\rSB}$ is small,
which is true by assumption. 
In such case, if there is no special symmetry, the second-order infidelity provides a good approximation to the full infidelity expression $\infid(\cE)\simeq \norm{\Omega_\rSB}_\infty^2$, and we may study the second-order infidelity as opposed to the full infidelity, which dramatically simplifies  calculations.

On the other hand, the error phase provides only a rough indicator of the 
channel noise strength and could go wrong if special symmetries present.
The bounds in \Eqref{eq:infid2-bound} hints the problem: the error phase is good at measuring the upper bound but fails at the lower bound. 
In fact, one can think of an extreme example: in some symmetry-protected subspace where $[H,\rhoS\otimes\rhoB]=0$, the whole evolution is noiseless, 
thus $\infid(\cE|\rhoS)=0$, but the error phase could be arbitrary. In some other cases where only $\infid\up{2}(\cE|\rho_\rS) = 0$ and higher order terms persist, the infidelity is no longer approximated by $\norm{\Omega_\rSB}^2$.

Inspired from the error phase, we also define two new functions for the channel distance and the channel infidelity by 
\begin{align}
    \trdis_{\max}(\alpha,\beta)&= \max_{\opnorm{\Omega}=(\alpha,\beta)}\trdis_{\max}(\cE),\\
    \infid_{\max}(\alpha,\beta)&= \max_{\opnorm{\Omega}=(\alpha,\beta)}\infid_{\max}(\cE),
\end{align}
where the $\trdis_{\max}(\cE)$ and $\infid_{\max}(\cE)$ are defined in \Eqref{eq:Dmax-channel} and \Eqref{eq:InFmax-channel} for 
$\cE$ generated by $\Omega$.
This allows us to establish a fine-grained hierarchy of functions to gauge performance. For channel distance, $\trdis_{\min}(\alpha,\beta) \le  \trdis_{\min}(\cE) \le \trdis(\cE|\rho_\rS) \le \trdis_{\max}(\cE) \le  \trdis_{\max}(\alpha,\beta)$;
 and for the channel $\infid_{\min}(\alpha,\beta) \le  \infid_{\min}(\cE) \le \infid(\cE|\rho_\rS) \le \infid_{\max}(\cE) \le  \infid_{\max}(\alpha,\beta)$,
where  the functions with ``min'' subscript are defined by replacing the corresponding maximization with minimization. 
Through the $[H,\rho(0)]=0$ example we know that 
$\trdis_{\min}(\alpha,\beta) = \infid_{\min}(\alpha,\beta) =0$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\blue{(To come.)}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments
\blue{(Acknowledge Gu Yanwu, Jonas Tan, and Ryan Tiew, who did some of the first calculations of the breakeven points for PDD. Yanwu should be asked if he wants to be a co-author.)}


\newpage
\appendix
\section{Derivation for equations (\ref{eq:PDDnp-Gamma})}\label{app:PDDnpDerivation}
Here we explain the detailed steps to derive Eqs.~\!(\ref{eq:PDDnp-Gamma}).
In the following, we make no practical distinction between the notations $I,X,Y,Z$ and $\sigma_0,\sigma_1,\sigma_2,\sigma_3$ except that we prefer to use the former 
expression for unitary transformations and the latter for Lie algebra elements.

First, using their definitions, we can rewrite $\upe^{-\upi\Gamma_i}\, (i=0,1,2,3)$  in a more uniformed manner: 
\begin{subequations} \label{app:PDDnp-expGamma}
 \begin{align}
 \label{app:PDDnp-expGamma3}
\upe^{-\upi \Gamma_3} &=\wt Z Z &&=
Z \upe^{-\upi  \tfrac{\pi}{2} \sigma_3 -\upi \eta \sigma_3\Gamma''\sigma_3},\\
\label{app:PDDnp-expGamma2}
\upe^{-\upi \Gamma_2} &= Z \wt X Y &&=
X \upe^{+\upi  \tfrac{\pi}{2} \sigma_1 -\upi \eta \sigma_2\Gamma'\sigma_2},\\
\label{app:PDDnp-expGamma1}
\upe^{-\upi \Gamma_1} &= Y \wt Z X &&=
Z \upe^{+\upi  \tfrac{\pi}{2} \sigma_3 -\upi \eta \sigma_1\Gamma''\sigma_1},\\
\label{app:PDDnp-expGamma0}
\upe^{-\upi \Gamma_0} &= X \wt X &&= 
X \upe^{-\upi  \tfrac{\pi}{2} \sigma_1 -\upi \eta\Gamma'}.
\end{align}
\end{subequations}
Notice that here we have ignored the multiplicative factor $(-i)$ in \Eqref{app:PDDnp-expGamma2} and \Eqref{app:PDDnp-expGamma1} since they contribute to global phase factor only.

The goal is to calculate $\Gamma_i$ to the leading order in the smallness $\eta$.
To achieve this, we cite a formula from matrix group theory (see e.g. book \cite{rossmann2006lie} page 15):
\begin{equation}
 \frac{\dd}{\dd t} \upe^{X} = \upe^{X} \frac{1- \upe^{-\ad_X}}{\ad_X}\frac{\dd X}{\dd t},
\end{equation}
where $X$ is matrix-valued differentiable function of the scalar  variable $t$.
With the knowledge for taking derivatives, we can use Taylor expansion to derive the following approximation formula:
\begin{equation}\label{app:approx-liealgebra}
\begin{aligned}
  \upe^{-A} \upe^{A+ t B} &= 1 + t\, \frac{1-\upe^{-\ad_A}}{\ad_A} B +\cO(t^2)\\
 &= \exp\left[t\, \frac{1-\upe^{-\ad_A}}{\ad_A} B + \cO(t^2)\right],
\end{aligned}
\end{equation}
for general matrix operators $A$ and $B$ independent of the small real number $t$.
Apply \Eqref{app:approx-liealgebra}  to Eqs.~\!(\ref{app:PDDnp-expGamma}), we obtain the following expressions for $\Gamma_i$ :
\begin{subequations} \label{app:PDDnp-Gamma}
\begin{align}\label{app:PDDnp-Gamma3}
  \Gamma_3 &= \eta\, \frac{1-\upe^{-\frac{\pi}{2\upi} \ad_Z}}{ \frac{\pi}{2\upi} \ad_Z} (\sigma_3\Gamma''\sigma_3) + \cO(\eta^2),\\
  \Gamma_2 &= \eta\, \frac{1-\upe^{\frac{\pi}{2\upi} \ad_X}}{ -\frac{\pi}{2\upi} \ad_X} (\sigma_2\Gamma'\sigma_2) + \cO(\eta^2),\\
  \Gamma_1 &= \eta\, \frac{1-\upe^{\frac{\pi}{2\upi} \ad_Z}}{-\frac{\pi}{2\upi} \ad_Z} (\sigma_1\Gamma''\sigma_1) + \cO(\eta^2),\\
  \Gamma_0 &= \eta\, \frac{1-\upe^{-\frac{\pi}{2\upi} \ad_X}}{ \frac{\pi}{2\upi} \ad_X} (\Gamma') + \cO(\eta^2).
\end{align}
\end{subequations}
The expressions in Eqs.~\!(\ref{app:PDDnp-Gamma}) can be further calculated
by writing out the series expansion for the leading order terms in $\eta$. 
Let us focus on $\Gamma_3$, the leading oder term of which, according to \Eqref{app:PDDnp-Gamma3},  involves in the operator series:
\begin{equation}\label{app:PDDnp-G3series}
\sum_{k=0}^\infty \frac{(-\pi)^k }{(k+1)!}
 \left(\frac{1}{2\upi }\ad_Z\right)^k(\sigma_3 \Gamma''\sigma_3).
\end{equation}
Having introduced the decomposition for $\Gamma''$, we have
\begin{equation}
 \sigma_3\Gamma''\sigma_3 = \sigma_0 \otimes B'_0 -\sigma_1 \otimes B'_1
  -\sigma_2 \otimes B'_2 +\sigma_3 \otimes B'_3.
\end{equation}
We may explicitly calculate the commutator $[Z,\sigma_3\Gamma''\sigma_3]$ and higher order nested commutators in \Eqref{app:PDDnp-G3series}. By inspection, the results fall in a total of four possible cases:
\begin{equation}
\begin{aligned}
  \Bigl(\frac{1}{2\upi}\ad_Z\Bigr)^{4n+1} (\sigma_3\Gamma''\sigma_3) &= 
 -\, \sigma_2 \otimes B_1'' + \sigma_1\otimes B''_2,\\
   \Bigl(\frac{1}{2\upi}\ad_Z\Bigr)^{4n+2} (\sigma_3\Gamma''\sigma_3) &= 
 +\,\sigma_1 \otimes B_1'' + \sigma_2\otimes B''_2,\\
  \Bigl(\frac{1}{2\upi}\ad_Z\Bigr)^{4n+3} (\sigma_3\Gamma''\sigma_3) &= 
 +\,\sigma_2 \otimes B_1'' - \sigma_1\otimes B''_2,\\
  \Bigl(\frac{1}{2\upi}\ad_Z\Bigr)^{4n+4} (\sigma_3\Gamma''\sigma_3) &= 
 -\, \sigma_1 \otimes B_1'' - \sigma_2\otimes B''_2,\\
\end{aligned}
\end{equation}
for integer $n\ge0$. Hence, we can calculate (\ref{app:PDDnp-G3series}) by 
\begin{equation}
\begin{aligned}
  (\cdots)={} &\sigma_0 \otimes B_0'' + \sigma_3 \otimes B_3''\\
 &\begin{aligned}
  &-\bigl(1-\frac{\pi^2}{3!}+\frac{\pi^4}{5!}+\cdots\bigr) \sigma_1 \otimes B_1''\\
  &+\bigl(\frac{\pi}{2!}-\frac{\pi^3}{4!}+\frac{\pi^5}{6!}+\cdots\bigr) \sigma_2 \otimes B_1''\\
  &-\bigl(1-\frac{\pi^2}{3!}+\frac{\pi^4}{5!}+\cdots\bigr) \sigma_2 \otimes B_2''\\
  &-\bigl(\frac{\pi}{2!}-\frac{\pi^3}{4!}+\frac{\pi^5}{6!}+\cdots\bigr)\sigma_1 \otimes B_2''
 \end{aligned}\\
 ={} & \sigma_0 \otimes B_0'' + \sigma_3 \otimes B_3''-\frac{\sin\pi}{\pi} (\sigma_1 \otimes B_1'' + \sigma_2 \otimes B_2'')\\
&+\frac{1-\cos\pi}{\pi} (\sigma_2 \otimes B_1'' - \sigma_1 \otimes B_2'')\\
={}&\sigma_0 \otimes B_0'' 
-\frac{2}{\pi}  \sigma_1 \otimes B_2''
+\frac{2}{\pi} \sigma_2 \otimes B_1'' + \sigma_3 \otimes B_3''.
\end{aligned}
\end{equation}
This leads to the expression for $\Gamma_3$ in \Eqref{eq:PDDnp-Gamma}.
One can proceed to verify $\Gamma_2$, $\Gamma_1$ and $\Gamma_0$ using similar steps. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analyzing the \texorpdfstring{$\CDDn$}{CDDn} dynamics}\label{app:CDD}

% It was suggested by the authors of CDD that the decoupling order for $\mathrm{CDD}_n$  is $n$ \cite{khodjasteh2005fault}. This statement is correct, but their proof is logically flawed. Given its importance, here we explain why the original proof is insufficient and  provide a rigorous proof for the decoupling order.
The unitary dynamics $U_n$ for $\CDDn$ can be completely described by its Hermitian generator (dimensionless Hamiltonian), $\Omega_n \equiv\upi\log(U_n)$.
It is more convenient to focus on the generators and regard 
DD as transformation among the generators.

At the ground level, we have the bare Hamiltonian $\Omega\equiv\tau H$.
At the first level, CDD produces $\Omega_1\equiv \Omega_{\mathsf{PDD}}$, which can be further expressed as a series
 $\sum_{m=1}^\infty \Omega_1\up{m}$ through Magnus expansion. 
 To characterize this process, we introduce the $\cD$ and $\cD\up{m}$ 
 maps, defined through:
 \begin{equation}
  \Omega_1 = \cD(\Omega), \quad \Omega_1\up{m} = \cD\up{m}(\Omega),
 \end{equation}
with $\cD = \sum_{m=1}^\infty \cD\up{m}$
in correspondence with the Magnus series. In particular, $\cD\up{1}$ and $\cD\up{2}$ are already given in the main text through \Eqref{eq:PDDMag1} and \Eqref{eq:PDDMag2}. 
Higher level concatenations are defined by the iteration map 
\begin{equation}\label{eq:CDD-update}
    \Omega_n = \cD(\Omega_{n-1}) = \sum_{m=1}^\infty \cD\up{m}(\Omega_{n-1}).
\end{equation}
Backtracking the map from level $n$ to level $0$, we have
$\Omega_{n} = (\cD)^{n}(\Omega)$. In the end, 
$\Omega_{n}$ can be expanded as a Magnus series in the bare Hamiltonian. 
\begin{equation}\label{eq:CDD-magnus}
\Omega_{n} =\Bigl(\sum_{m=1}^\infty \cD\up{m}\Bigr)^{n}(\Omega)=\sum_{m=1}^\infty \Omega_{n}\up{m},
\end{equation}
where $\Omega_{n}\up{m}$ is the $m$th order term for $\Omega_{n}$ in $\Omega$ such that $\Omega_{n}\up{m}  \sim  \norm{\Omega}^m$.

The full $\Omega_{n}$ is typically difficult to solve.
To estimate $\Omega_{n}$, it suffice to find an analytically solvable estimator $\Ohat_{n}$ which reflects leading order behavior of the full series. 
The leading order behavior is required separately for the pure-bath part and the system-bath coupling part, as these two parts can be of different orders. 
Formally, we define an estimator-error pair 
\begin{equation}
 \Omega_{n} = \Ohat_{n} + \delta\Omega_{n}.
\end{equation}
For a faithful estimator, the error term $ \delta\Omega_{n}$ must be of higher order smallness than the estimator both in the pure-bath part and the coupling part. To better quantify this statement, we take the two-component norm for both 
$\delta\Omega_{n}$ and $\Ohat_{n}$. This faithfulness condition demands
\begin{equation}\label{eq:tcn-esterr}
\opnorm{\delta\Omega_{n}}\equiv
\begin{pmatrix}
\delta\alpha_{n}\\
\delta\beta_{n}
\end{pmatrix}
\ll 
\opnorm{\Ohat_{n}}\equiv\begin{pmatrix}
\widehat\alpha_{n}\\
\widehat\beta_{n}
\end{pmatrix},
\end{equation}
where the comparison is implied for both components and should be understood by comparing the leading powers of the polynomials. Namely,
a ``smaller'' polynomial should have a larger leading power. 


% After taking the two-component norm and applying triangular inequality for \Eqref{eq:est+err}, we find,
% \begin{equation}\label{eq:lu}
%     \widehat\beta_{n}-\delta\beta_{n}\le  \beta_{n}\le \widehat\beta_{n}+\delta\beta_{n}.
% \end{equation}
% According to \Eqref{eq:nth-order-alternative}, the $n$th-order decoupling condition requires $\beta_{n}$ to be an $(n+1)$th order polynomial in $\alpha$ and $\beta$. It now suffices to show that $\widehat\beta_{n}$ is an $(n+1)$th order polynomial.

The original CDD paper (Ref.\cite{khodjasteh2005fault}) constructed an estimator by keeping the first two Magnus terms for each iteration step. In
our notation:
\begin{equation}\label{eq:estimator-trunc}
    \Ohat_{n} \equiv (
    \cD\up{1} + 
    \cD\up{2}) (\Ohat_{n-1}) = \big(
    \cD\up{1} + 
    \cD\up{2}\big)^n (\Omega).
\end{equation}
After a little bit algebra, the estimator can shown to be given by the formula:
\begin{align}\label{eq:cdd-estimator}
\Ohat_{n} 
={} & \sigma_0 \otimes 4^n B_0 \notag \\
+\ & \sigma_1 \otimes (-\upi)^{n} 2^{n(n+1)} \ad_{B_0}^{n}(B_1)\\ 
+\ & \sigma_2 \otimes (-\upi)^{n} 2^{n^2} \ad_{B_0}^{n-\!1}( \,[B_0,B_2] - \upi \{B_1,B_3\} \,). \notag
\end{align} 
 For simplicity, let us make the recognition that $\norm{B_i}\simeq\tau$, where $\simeq$ represents that the both sides have the same leading power when written as a polynomial in $\tau$, ignoring any coefficient.
According to \Eqref{eq:cdd-estimator}, we have,
\begin{equation}
\opnorm{\Ohat_{n}} =
\begin{pmatrix}
\widehat\alpha_{n}\\
\widehat\beta_{n}
\end{pmatrix}
\simeq
\begin{pmatrix}
\tau\\
\tau^{n+1}
\end{pmatrix}.
\end{equation}
To show that $\Ohat_{n}$ is indeed faithful, $\delta\alpha_{n}$ and $\delta\beta_{n}$ need to be of higher order smallness compared to $\widehat\alpha_{n}$ and $\widehat\beta_{n}$. Indeed, we claim that:
\begin{equation}\label{eq:cdd-error-bounds}
\begin{pmatrix}
\delta\alpha_{n}\\
\delta\beta_{n} 
\end{pmatrix}
\lesssim
\begin{pmatrix}
\tau^3\\
\tau^{n+2} 
\end{pmatrix}.
\end{equation}
We prove this assertion by mathematical induction.

\emph{Proof:}
At $n=1$, the estimation error comes solely from the Magnus series truncation for PDD, lead by the third order term:
\begin{equation}
\opnorm{\delta\Omega_{1}} = \opnorm{\sum_{m=3}^\infty \Omega_{1}\up{m}}
\simeq \opnorm{\Omega_{1}\up{3}} \simeq
\begin{pmatrix}
\tau^3\\
\tau^3
\end{pmatrix}.
\end{equation}
At higher truncation level, the estimation error is related with the lower level terms by:
\begin{equation}\label{eq:error update}
 \begin{aligned}
\delta\Omega_{n+1} 
&=\cD(\Omega_{n})-(\cD\up{1}+\cD\up{2})(\Ohat_{n})\\
&= \cD\up{1}(\delta\Omega_{n})+ \sum_{m=2}^\infty \cD\up{m}(\Omega_{n})-\cD\up{2}(\Ohat_{n}),
\end{aligned} 
\end{equation}
where we have used the fact that $\cD\up{1}$ is a linear map. 
To properly bound the size of the error term, we take the two-component norm on both sides of \Eqref{eq:error update}:
\begin{equation}
\begin{aligned}\label{eq:cdd-error-3terms}
\opnorm{\delta\Omega_{n+1} }
&\lesssim \opnorm{ \cD\up{1}(\delta\Omega_{n}) } + 
\opnorm{\sum_{m=3}^\infty \cD\up{m}( \Omega_{n})} \\
&+ \opnorm{ \cD\up{2}(\Omega_n)-\cD\up{2}(\Ohat_{n})}.
\end{aligned}    
\end{equation}
We now need to show $\opnorm{\delta\Omega_{n+1}}\lesssim(\tau^3,\tau^{n+3})$.
The original CDD paper by Khodjasteh and Lidar has only showed that the higher order Magnus series $\sum_{m=3}^\infty\cD\up{m}(\Ohat_{n})$ is small.
However \Eqref{eq:error update} suggests that this argument is not sufficient: as
the estimate error $\delta\Omega_{n+1}$ comes not only  from the truncation error of the same level, but also propagates from the lower level error $\delta\Omega_{n}$. 
We now examine the size of these terms.
The first term in (\ref{eq:cdd-error-3terms}) is straightforward,
\begin{equation*}
\opnorm{\cD\up{1}(\delta\Omega_{n})} = \begin{pmatrix}
4 \delta\alpha_{n} \\
0
\end{pmatrix}\simeq
\begin{pmatrix}
\tau^3 \\
0
\end{pmatrix}.
\end{equation*}
The second term involves a infinite sum of Magnus terms higher than third order, which is lead by the third order term, whose 
size can be bounded by 
\begin{equation*}
\opnorm{\cD\up{3}(\Omega_n)}\lesssim
\begin{pmatrix}
\beta_{n}^2 (\alpha_{n}+\beta_{n}) \\
\beta_{n} (\alpha_{n}+\beta_{n})^2
\end{pmatrix}
\simeq \begin{pmatrix}
\tau^{2n+2}\\
\tau^{n+3}
\end{pmatrix},
\end{equation*}
where we have used the induction hypothesis 
$\alpha_{n}\simeq\widehat\alpha_{n}\simeq\tau$ and 
$\beta_{n}\simeq\widehat\beta_{n}\simeq \tau^{n+1}$ .
The estimation for $\opnorm{\cD\up{3}(\Omega_n)}$ can be done by explicitly calculating the third order Magnus term for PDD; or by making  the clever observation that for higher Magnus terms, 
$B_{i\neq0}$ is involved in the coupling part for at least once and 
 the pure bath part for at least two times.  
To bound the third term in (\ref{eq:cdd-error-3terms}), we need to calculate the difference $\cD\up{2}(\Ohat+\delta\Omega) - \cD\up{2}(\Ohat)$.
Using the expression for the second order Magnus term, we obtain
\begin{equation*}
\begin{split}
&\opnorm[\big]{\cD\up{2}(\Omega) - \cD\up{2}(\Ohat)} 
\lesssim\begin{pmatrix}
    0\\
    \delta\alpha_{n} \beta_{n} +\alpha_{n} \delta\beta_{n}
\end{pmatrix}\simeq
\begin{pmatrix}
    0\\
    \tau^{n+3}
\end{pmatrix}.
\end{split}
\end{equation*}
Since all three terms are bounded by $(\tau_0^3, \tau_0^{n+3})^\transpose$, so is their sum. This proves our assertion \Eqref{eq:cdd-error-bounds}. \qed

\smallskip

We have now showed that the estimator constructed through 
\Eqref{}{eq:estimator-trunc} is indeed faithful.
Hence it must be the case that $\Ohat_n$ contains at least the leading order terms of the full $\Omega_n$. We are now confident in using the estimator \Eqref{eq:cdd-estimator} to study the full $\Omega_{n}$ of $\mathrm{CDD}_n$. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{references}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix


\end{document}
